import subprocess
import sys
import shutil
import os
import time
import datetime # å¼•å…¥æ—¶é—´å¤„ç†åº“
from pathlib import Path
import torch 
import logging 
import json 
import numpy as np 
import math

# è®¾ç½® Nerfstudio å†…éƒ¨æ—¥å¿—çº§åˆ«ï¼Œé¿å…å¤§é‡æ‚é¡¹è¾“å‡ºå¹²æ‰°
logging.getLogger('nerfstudio').setLevel(logging.ERROR) 

# ================= é…ç½®åŒºåŸŸ =================
# Linux ä¸‹çš„ä¸´æ—¶é«˜é€Ÿå·¥ä½œåŒº (è®­ç»ƒæ—¶çš„ä¸´æ—¶æ–‡ä»¶æ”¾è¿™é‡Œï¼Œé€Ÿåº¦å¿« 10 å€)
LINUX_WORK_ROOT = Path.home() / "braindance_workspace"

# ================= è¾…åŠ©å·¥å…·ï¼šæ—¶é—´æ ¼å¼åŒ– =================
def format_duration(seconds):
    """å°†ç§’æ•°è½¬æ¢ä¸º HH:MM:SS æ ¼å¼"""
    return str(datetime.timedelta(seconds=int(seconds)))

# ================= æ™ºèƒ½åœºæ™¯åˆ†æç®—æ³• =================
def analyze_scene_type(json_path):
    """
    åˆ†æ transforms.json ä¸­çš„ç›¸æœºå§¿æ€ï¼Œåˆ¤æ–­æ˜¯â€œå‘å†…æ‹æ‘„(ç‰©ä½“)â€è¿˜æ˜¯â€œå‘å¤–æ‹æ‘„(åœºæ™¯)â€ã€‚
    è¿”å›å»ºè®®çš„ ns-train å‚æ•°åˆ—è¡¨ã€‚
    """
    print(f"\nğŸ¤– [AI åˆ†æ] æ­£åœ¨è¯»å–ç›¸æœºè½¨è¿¹ä»¥åˆ¤æ–­åœºæ™¯ç±»å‹...")
    
    try:
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        frames = data["frames"]
        if not frames:
            return [], "unknown"

        # 1. æå–æ‰€æœ‰ç›¸æœºä½ç½®
        positions = []
        forward_vectors = []
        
        for frame in frames:
            c2w = np.array(frame["transform_matrix"])
            # ä½ç½®æ˜¯ç¬¬4åˆ—å‰3è¡Œ
            pos = c2w[:3, 3]
            positions.append(pos)
            
            # è®¡ç®—å‰å‘å‘é‡ (Nerfstudio/OpenGL ä¸­ï¼ŒZè½´æŒ‡å‘ç›¸æœºåæ–¹ï¼Œæ‰€ä»¥å‰å‘æ˜¯ -Z)
            rot = c2w[:3, :3]
            forward = rot @ np.array([0, 0, -1]) 
            forward_vectors.append(forward)
            
        positions = np.array(positions)
        forward_vectors = np.array(forward_vectors)
        
        # 2. è®¡ç®—åœºæ™¯å‡ ä½•ä¸­å¿ƒ (æ‰€æœ‰ç›¸æœºçš„ä¸­å¿ƒç‚¹)
        center_of_mass = np.mean(positions, axis=0)
        
        # 3. åˆ¤æ–­æ¯ä¸ªç›¸æœºæ˜¯å¦çœ‹å‘ä¸­å¿ƒ
        vec_to_center = center_of_mass - positions
        norms = np.linalg.norm(vec_to_center, axis=1, keepdims=True)
        norms[norms < 1e-6] = 1.0 
        vec_to_center_norm = vec_to_center / norms
        
        # ç‚¹ç§¯ï¼šForward Â· ToCenter
        dot_products = np.sum(forward_vectors * vec_to_center_norm, axis=1)
        
        # 4. ç»Ÿè®¡â€œçœ‹å‘ä¸­å¿ƒâ€çš„ç›¸æœºæ¯”ä¾‹
        looking_inward_ratio = np.sum(dot_products > 0) / len(frames)
        
        print(f"    -> ç›¸æœºèšåˆåº¦: {looking_inward_ratio:.2f} (1.0ä»£è¡¨å®Œå…¨å‘å†…ï¼Œ0.0ä»£è¡¨å®Œå…¨å‘å¤–)")

        # 5. å†³ç­–é€»è¾‘ (é˜ˆå€¼ 0.6)
        if looking_inward_ratio > 0.6:
            print("ğŸ’¡ åˆ¤å®šç»“æœï¼šã€ç‰©ä½“æ‰«ææ¨¡å¼ (Inward)ã€‘")
            print("    -> ç­–ç•¥ï¼šç›¸æœºå›´ç€ç‰©ä½“è½¬ã€‚å¯ç”¨ç´§å‡‘è£å‰ª(2.0~6.0)ï¼Œèšç„¦ä¸­å¿ƒç‰©ä½“ï¼Œå»é™¤èƒŒæ™¯ã€‚")
            return ["--pipeline.model.enable-collider", "True", 
                    "--pipeline.model.collider-params", "near_plane", "2.0", "far_plane", "6.0"], "object"
        else:
            print("ğŸ’¡ åˆ¤å®šç»“æœï¼šã€å…¨æ™¯/å®¤å†…æ¨¡å¼ (Outward)ã€‘")
            print("    -> ç­–ç•¥ï¼šç›¸æœºåœ¨å†…éƒ¨å‘å¤–çœ‹ï¼Œæˆ–ç›´çº¿æ‰«æã€‚æ”¾å®½è£å‰ª(0.05~100.0)ï¼Œä¿ç•™å¢™å£å’Œè¿œæ™¯ã€‚")
            return ["--pipeline.model.enable-collider", "True", 
                    "--pipeline.model.collider-params", "near_plane", "0.05", "far_plane", "100.0"], "scene"

    except Exception as e:
        print(f"âš ï¸ åˆ†æå¤±è´¥ ({e})ï¼Œå°†ä½¿ç”¨é»˜è®¤ä¿å®ˆå‚æ•°ã€‚")
        # é»˜è®¤ä¿å®ˆï¼šä¸ä¹±åˆ‡ï¼Œè®¾å¤§èŒƒå›´
        return ["--pipeline.model.enable-collider", "True", 
                "--pipeline.model.collider-params", "near_plane", "0.1", "far_plane", "50.0"], "unknown"

# ================= ä¸»æµç¨‹ =================

def run_pipeline(video_path, project_name):
    # --- å…¨å±€è®¡æ—¶å¼€å§‹ ---
    global_start_time = time.time()
    print(f"\nğŸš€ [BrainDance Engine] å¯åŠ¨ä»»åŠ¡: {project_name}")
    print(f"ğŸ•’ å¼€å§‹æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. è·¯å¾„è§£æ
    video_src = Path(video_path).resolve()
    
    # å®šä¹‰ä¸´æ—¶å·¥ä½œç›®å½•
    work_dir = LINUX_WORK_ROOT / project_name
    data_dir = work_dir / "data"
    output_dir = work_dir / "outputs"
    
    # ================= [æ™ºèƒ½æ£€æŸ¥] æ–­ç‚¹ç»­ä¼ é€»è¾‘ =================
    transforms_file = data_dir / "transforms.json"
    env = os.environ.copy()
    env["QT_QPA_PLATFORM"] = "offscreen" # é˜²æ­¢æ— å¤´æ¨¡å¼å´©æºƒ

    # ================= [Step 1] æ•°æ®é¢„å¤„ç† (Manual Split) =================
    step1_start = time.time()
    
    if transforms_file.exists():
        print(f"\nâ© [Step 1] æ£€æµ‹åˆ°å·²å­˜åœ¨çš„ COLMAP æ•°æ®: {transforms_file}ï¼Œè·³è¿‡é¢„å¤„ç†ã€‚")
    else:
        print(f"\nğŸ†• [æ–°ä»»åŠ¡] æœªæ‰¾åˆ°å†å²æ•°æ®ï¼Œå¼€å§‹åˆå§‹åŒ–å·¥ä½œåŒº...")
        if work_dir.exists():
            shutil.rmtree(work_dir)
        work_dir.mkdir(parents=True)
        data_dir.mkdir(parents=True)
        
        print(f"ğŸ“‚ [IO ä¼˜åŒ–] æ­£åœ¨å°†æ•°æ®è¿ç§»è‡³ Linux åŸç”Ÿç›®å½•åŠ é€Ÿ...")
        video_dst = work_dir / video_src.name
        shutil.copy(str(video_src), str(video_dst))

        print(f"\nğŸ¥ [1/3] è§†é¢‘æŠ½å¸§ä¸ä½å§¿è§£ç®— (COLMAP)")

        # 1.1 æ‰‹åŠ¨è°ƒç”¨ FFmpeg
        print("    -> 1.1 FFmpeg: æŠ½å¸§åˆ° 1080P å®½åˆ†è¾¨ç‡ (4 FPS) å†™å…¥åŸç”Ÿç›®å½•")

        extracted_images_dir = data_dir / "images"
        extracted_images_dir.mkdir(parents=True, exist_ok=True)

        # FFmpeg å‘½ä»¤
        ffmpeg_cmd = [
            "ffmpeg", "-y", "-i", str(video_dst), 
            "-vf", "fps=5",  # <--- ä¿æŒåŸå§‹åˆ†è¾¨ç‡ï¼Œ4 FPS
            "-q:v", "2", 
            str(extracted_images_dir / "frame_%05d.jpg")
        ]
        subprocess.run(ffmpeg_cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) 

        # --- å›¾ç‰‡æ•°é‡æ£€æŸ¥ (Limit to 20000 - å®é™…ä¸Šä¸åˆ é™¤ï¼Œä»…ä½œä¸ºä¿é™©) ---
        all_images = sorted(list(extracted_images_dir.glob("*.jpg")))
        num_images = len(all_images)
        MAX_IMAGES = 20000

        if num_images > MAX_IMAGES:
            print(f"    âš ï¸ å›¾ç‰‡æ•°é‡ ({num_images}) è¶…è¿‡ä¸Šé™ {MAX_IMAGES}ï¼Œæ­£åœ¨è¿›è¡Œå‡åŒ€é‡‡æ ·...")
            indices_to_keep = set([int(i * (num_images - 1) / (MAX_IMAGES - 1)) for i in range(MAX_IMAGES)])
            deleted_count = 0
            for idx, img_path in enumerate(all_images):
                if idx not in indices_to_keep:
                    os.remove(img_path) 
                    deleted_count += 1
            print(f"    âœ… å·²åˆ é™¤ {deleted_count} å¼ å¤šä½™å›¾ç‰‡ï¼Œå‰©ä½™ {MAX_IMAGES} å¼ ç”¨äºåºåˆ—åŒ¹é…ã€‚")
        else:
            print(f"    âœ… å›¾ç‰‡æ•°é‡ ({num_images}) æœªè¶…æ ‡ï¼Œæ— éœ€å¤„ç†ã€‚")
        
        # 1.2 è°ƒç”¨ ns-process-data images (COLMAP è§£ç®—)
        print("    -> 1.2 Nerfstudio: è°ƒç”¨ COLMAP è¿›è¡Œä½å§¿è§£ç®— (æ¨¡å¼: Sequential, å®æ—¶æ—¥å¿—)")

        colmap_data_dir = data_dir 

        cmd_colmap = [
            "ns-process-data", "images",
            "--data", str(extracted_images_dir),
            "--output-dir", str(colmap_data_dir),
            "--verbose",
            # "--matching-method", "sequential"  <--- å·²ç¡®è®¤ä½¿ç”¨é»˜è®¤/è‡ªåŠ¨æ¨¡å¼
        ]
        
        # --- ä½¿ç”¨ Popen å®ç°â€œå®æ—¶ç›´æ’­â€æ—¥å¿— ---
        full_log_content = [] 
        
        try:
            with subprocess.Popen(
                cmd_colmap, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.STDOUT, 
                text=True, 
                env=env,
                bufsize=1 
            ) as process:
                for line in process.stdout:
                    print(line, end='') 
                    full_log_content.append(line) 
                process.wait()
                if process.returncode != 0:
                    raise subprocess.CalledProcessError(process.returncode, cmd_colmap)
        except Exception as e:
            print(f"\nâŒ COLMAP è¿è¡Œå‡ºé”™: {e}")
            raise e

        log_str = "".join(full_log_content)
        
        # è´¨é‡æ£€æŸ¥
        if "COLMAP only found poses" in log_str:
            print("\nğŸš¨ğŸš¨ğŸš¨ æ£€æµ‹åˆ° COLMAP æ•°æ®è´¨é‡æå·®ï¼è‡ªåŠ¨åœæ­¢è®­ç»ƒã€‚")
            print("âŒ é”™è¯¯åŸå› ï¼šè§†é¢‘è´¨é‡å¤ªå·®æˆ–åœºæ™¯åå…‰ï¼Œåªæœ‰æå°‘æ•°å›¾ç‰‡æ‰¾åˆ°äº†ä½å§¿ã€‚")
            shutil.rmtree(data_dir)
            raise RuntimeError("COLMAP æ•°æ®è´¨é‡ä¸åˆæ ¼ï¼Œæµç¨‹åœæ­¢ã€‚")

        if not transforms_file.exists():
            raise FileNotFoundError("COLMAP å¤±è´¥ï¼Œæœªæ‰¾åˆ° transforms.json æ–‡ä»¶ã€‚")
            
    step1_duration = time.time() - step1_start
    print(f"â±ï¸ [Step 1 å®Œæˆ] è€—æ—¶: {format_duration(step1_duration)}")

    # ================= [Step 2] æ¨¡å‹è®­ç»ƒ =================
    step2_start = time.time()
    
    # æŸ¥æ‰¾æ˜¯å¦æœ‰å·²å®Œæˆçš„è®­ç»ƒç»“æœ
    search_path = output_dir / project_name / "splatfacto"
    run_dirs = sorted(list(search_path.glob("*"))) if search_path.exists() else []

    if run_dirs:
        print(f"\nâ© [Step 2] æ£€æµ‹åˆ°å·²å®Œæˆçš„è®­ç»ƒç»“æœï¼š{run_dirs[-1].name}ï¼Œè·³è¿‡è®­ç»ƒã€‚")
    else:
        # === è°ƒç”¨æ™ºèƒ½åœºæ™¯åˆ†æï¼Œè·å–è£å‰ªå‚æ•° ===
        collider_args, scene_type = analyze_scene_type(transforms_file)
        
        print(f"\nğŸ§  [2/3] å¼€å§‹è®­ç»ƒ (RTX 5070 åŠ é€Ÿä¸­)")
        
        cmd_train = [
            "ns-train", "splatfacto",
            "--data", str(data_dir),
            "--output-dir", str(output_dir),
            "--experiment-name", project_name,
            
            # --- å¼ºåˆ¶ COLMAP åˆå§‹åŒ–å‚æ•° ---
            "--pipeline.model.random-init", "False", 
            "--pipeline.model.cull-alpha-thresh", "0.005",

            # === æ’å…¥ï¼šæ™ºèƒ½åˆ†æå¾—å‡ºçš„è£å‰ªå‚æ•° ===
            *collider_args,
            
            # --- è®­ç»ƒå‚æ•° ---
            "--max-num-iterations", "15000",
            "--vis", "viewer+tensorboard", 
            
            # --- å…³é”®ä¿®å¤ï¼šè®­ç»ƒå®Œæˆåè‡ªåŠ¨é€€å‡ºï¼Œæ— éœ€ Ctrl+C ---
            "--viewer.quit-on-train-completion", "True",
            
            # --- Dataparser å­å‘½ä»¤ ---
            "colmap",
        ]
        subprocess.run(cmd_train, check=True, env=env)

    step2_duration = time.time() - step2_start
    print(f"â±ï¸ [Step 2 å®Œæˆ] è€—æ—¶: {format_duration(step2_duration)}")

    # ================= [Step 3] å¯¼å‡ºç»“æœ =================
    step3_start = time.time()
    print(f"\nğŸ’¾ [3/3] å¯¼å‡ºç»“æœ")
    
    if not run_dirs:
        run_dirs = sorted(list(search_path.glob("*")))

    if not run_dirs:
        print("âŒ é”™è¯¯ï¼šè®­ç»ƒç»“æœç›®å½•ä¸ºç©ºï¼Œæ— æ³•å¯¼å‡ºã€‚è¯·æ£€æŸ¥ Step 2 æ˜¯å¦æˆåŠŸã€‚")
        return None
        
    latest_run = run_dirs[-1]
    config_path = latest_run / "config.yml"
    
    cmd_export = [
        "ns-export", "gaussian-splat",
        "--load-config", str(config_path),
        "--output-dir", str(work_dir)
    ]
    
    subprocess.run(cmd_export, check=True, env=env)
    
    print("â³ ç­‰å¾…æ–‡ä»¶å†™å…¥ç£ç›˜...")
    time.sleep(5) 

    print(f"âœ… å¯¼å‡ºæˆåŠŸï¼æ–‡ä»¶åº”å·²ç”Ÿæˆäº {work_dir / 'point_cloud.ply'}")
    step3_duration = time.time() - step3_start
    print(f"â±ï¸ [Step 3 å®Œæˆ] è€—æ—¶: {format_duration(step3_duration)}")

    # ================= [Step 4] ç»“æœå›ä¼  =================
    print(f"\nğŸ“¦ [IO åŒæ­¥] æ­£åœ¨å°†ç»“æœå›ä¼ è‡³ Windows é¡¹ç›®ç›®å½•...")
    
    target_dir = Path(__file__).parent / "results"
    target_dir.mkdir(exist_ok=True)

    temp_ply_default = work_dir / "point_cloud.ply"
    temp_ply_alt = work_dir / "splat.ply"
    
    if temp_ply_default.exists():
        temp_ply = temp_ply_default
    elif temp_ply_alt.exists():
        temp_ply = temp_ply_alt
    else:
        temp_ply = None
        
    transforms_src = data_dir / "transforms.json"
    final_webgl_poses = target_dir / "webgl_poses.json"
    final_ply = target_dir / f"{project_name}.ply"
    final_transforms = target_dir / "transforms.json"
    
    # --- å§¿æ€é¢„å¤„ç†é€»è¾‘ ---
    if transforms_src.exists():
        print("ğŸ”„ æ­£åœ¨ç”Ÿæˆ WebGL å‹å¥½å§¿æ€æ–‡ä»¶ (webgl_poses.json)...")
        try:
            with open(transforms_src, 'r') as f:
                data = json.load(f)
            
            webgl_frames = []
            for frame in data["frames"]:
                c2w_matrix = np.array(frame["transform_matrix"], dtype=np.float32)
                # è®¡ç®— W2C (è™½ç„¶è¿™é‡Œåªå­˜äº† C2Wï¼Œä½†å¯ä»¥é¢„ç•™é€»è¾‘)
                webgl_frames.append({
                    "file_path": frame["file_path"],
                    "pose_matrix_c2w": c2w_matrix.tolist() 
                })
                
            webgl_data = {
                "camera_model": data["camera_model"],
                "w": data["w"],
                "h": data["h"],
                "fl_x": data["fl_x"],
                "fl_y": data["fl_y"],
                "frames": webgl_frames
            }
            
            with open(final_webgl_poses, 'w') as f:
                json.dump(webgl_data, f, indent=4)
            print(f"âœ… WebGL å§¿æ€æ–‡ä»¶å·²ä¿å­˜è‡³: {final_webgl_poses.resolve()}")
        except Exception as e:
            print(f"âŒ å§¿æ€é¢„å¤„ç†å¤±è´¥: {e}")

    if temp_ply and temp_ply.exists():
        # å¤åˆ¶ PLY æ–‡ä»¶
        copy_ply_command_str = f"cp {str(temp_ply)} {str(final_ply)}"
        subprocess.run(copy_ply_command_str, check=True, shell=True)
        
        # å¤åˆ¶ transforms.json æ–‡ä»¶
        if transforms_src.exists():
            copy_transforms_cmd_str = f"cp {str(transforms_src)} {str(final_transforms)}"
            subprocess.run(copy_transforms_cmd_str, check=True, shell=True)
        
        # æ¸…ç† Linux ä¸´æ—¶æ–‡ä»¶
        shutil.rmtree(work_dir)
        print(f"ğŸ§¹ æ¸…ç†å®Œæˆ: å·²åˆ é™¤å·¥ä½œåŒº {work_dir}")
        
        # --- æœ€ç»ˆæ—¶é—´æ±‡æ€» ---
        total_time = time.time() - global_start_time
        print(f"\nâœ… =============================================")
        print(f"ğŸ‰ ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼å®‰å¿ƒç¡è§‰å§ã€‚")
        print(f"ğŸ“‚ æœ€ç»ˆæ¨¡å‹: {final_ply}")
        print(f"â±ï¸ æ€»å…±è€—æ—¶: {format_duration(total_time)}")
        print(f"âœ… =============================================")
        
        return str(final_ply)
    else:
        print("âŒ å¯¼å‡ºå¤±è´¥ï¼Œæœªæ‰¾åˆ° PLY æ–‡ä»¶ (point_cloud.ply æˆ– splat.ply)ã€‚")
        return None

if __name__ == "__main__":
    script_dir = Path(__file__).resolve().parent
    video_file = script_dir / "test.mp4" 
    
    if len(sys.argv) > 1:
        video_file = Path(sys.argv[1])

    if video_file.exists():
        # è¯·æ³¨æ„ï¼šå¦‚æœæ‚¨ä¹‹å‰å·²ç»è·‘è¿‡ Step 1 (COLMAP)ï¼Œè¯·æ‰‹åŠ¨åˆ é™¤ /home/ltx/braindance_workspace/scene_auto_sync/data/transforms.json æ–‡ä»¶ï¼Œä»¥å¼ºåˆ¶é‡æ–°è¿è¡Œ COLMAPï¼Œç¡®ä¿æ–°çš„å‚æ•°ç”Ÿæ•ˆï¼
        run_pipeline(video_file, "scene_auto_sync")
    else:
        print(f"âŒ æ‰¾ä¸åˆ°è§†é¢‘: {video_file}")