import os
import json
# 1. å¯¼å…¥å›½äº§æ¨¡å‹ç»„ä»¶
from langchain_community.chat_models import ChatTongyi
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.schema import Document

# === é…ç½®éƒ¨åˆ† ===
# é˜¿é‡Œäº‘ DashScope API Key (å» aliyun.com å¼€é€š)
os.environ["DASHSCOPE_API_KEY"] = "sk-xxxxxxxxxxxxxxxx" 

DATA_DIR = "./data"
DB_DIR = "./chroma_db_qwen"

# === æ ¸å¿ƒå‡½æ•° 1: åŠ è½½å¹¶ç»‘å®šæ•°æ® ===
def load_and_bind_data(directory):
    documents = []
    
    # 1. å…ˆæ‰«ææ‰€æœ‰çš„â€œåœºæ™¯æ–‡ä»¶â€ (scene_summary.json) å»ºç«‹ç´¢å¼•
    # ä½œç”¨ï¼šå»ºç«‹ scene_id -> åœºæ™¯æè¿° çš„æ˜ å°„ï¼Œæ–¹ä¾¿åé¢ç»™å›¾ç‰‡ç»‘å®šä¿¡æ¯
    scene_map = {} 
    
    for root, _, files in os.walk(directory):
        if "scene_summary.json" in files:
            with open(os.path.join(root, "scene_summary.json"), 'r', encoding='utf-8') as f:
                data = json.load(f)
                # å‡è®¾æ–‡ä»¶å¤¹åå­—å°±æ˜¯åœºæ™¯IDï¼Œä¾‹å¦‚ ./data/scene_01/
                scene_id = os.path.basename(root) 
                scene_map[scene_id] = data.get("summary", "")
                
                # == å­˜å…¥çˆ¶çº§ä¿¡æ¯ (3Dæ¨¡å‹) ==
                # è¿™æ ·ç”¨æˆ·æœâ€œç™½è‰²è§¦æ§ç¬”æ¨¡å‹â€æ—¶èƒ½æ‰¾åˆ°å®ƒ
                doc = Document(
                    page_content=data["summary"], # æœç´¢å†…å®¹
                    metadata={
                        "type": "model_summary",    # ç±»å‹ï¼šæ¨¡å‹æ€»è§ˆ
                        "scene_id": scene_id,       # ç»‘å®šID <--- æ ¸å¿ƒ
                        "file_path": os.path.join(root, "model.ply"), # å‡å®šæ¨¡å‹è·¯å¾„
                        "shooting_mode": data["shooting_strategy"]["mode"]
                    }
                )
                documents.append(doc)

    # 2. å†æ‰«ææ‰€æœ‰çš„â€œå›¾ç‰‡å¸§â€ (frame_xxxx.json)
    for root, _, files in os.walk(directory):
        scene_id = os.path.basename(root) # è·å–å½“å‰æ‰€åœ¨çš„åœºæ™¯ID
        
        for file in files:
            if file.startswith("frame_") and file.endswith(".json"):
                full_path = os.path.join(root, file)
                with open(full_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # == å­˜å…¥å­çº§ä¿¡æ¯ (å›¾ç‰‡) ==
                # è¿™é‡Œå®ç°äº†â€œç»‘å®šâ€ï¼šmetadata é‡Œæ—¢æœ‰è‡ªå·±çš„ filenameï¼Œä¹Ÿæœ‰çˆ¶äº²çš„ scene_id
                meta = {
                    "type": "image_frame",         # ç±»å‹ï¼šå›¾ç‰‡å¸§
                    "scene_id": scene_id,          # ç»‘å®šID <--- æ ¸å¿ƒï¼šæŒ‡å‘å±äºå“ªä¸ªæ¨¡å‹
                    "filename": data["filename"],
                    "file_path": os.path.join(root, data["filename"]), # å›¾ç‰‡çœŸå®è·¯å¾„
                    "quality": data.get("quality_score", 0),
                    # æŠŠçˆ¶çº§çš„èƒŒæ™¯çŸ¥è¯†ä¹Ÿæ”¾è¿›å»ï¼Œæ–¹ä¾¿åç»­æ£€ç´¢å±•ç¤º
                    "parent_context": scene_map.get(scene_id, "æœªçŸ¥åœºæ™¯") 
                }
                
                doc = Document(
                    page_content=data["description"], # æœç´¢å†…å®¹
                    metadata=meta
                )
                documents.append(doc)

    return documents

# === æ ¸å¿ƒå‡½æ•° 2: å›½äº§åŒ–å‘é‡åº“æ„å»º ===
def build_index(documents):
    # ä½¿ç”¨é˜¿é‡Œ DashScope çš„ embedding æ¨¡å‹ (text-embedding-v1 æˆ– v2)
    embeddings = DashScopeEmbeddings(model="text-embedding-v1")
    
    vector_db = Chroma.from_documents(
        documents=documents,
        embedding=embeddings,
        persist_directory=DB_DIR
    )
    return vector_db

# === æ ¸å¿ƒå‡½æ•° 3: æ£€ç´¢ä¸å®šä½ ===
def search_engine(query):
    embeddings = DashScopeEmbeddings(model="text-embedding-v1")
    db = Chroma(persist_directory=DB_DIR, embedding_function=embeddings)
    
    # æ£€ç´¢ Top 3
    results = db.similarity_search(query, k=3)
    
    print(f"\nç”¨æˆ·æé—®: {query}")
    print("-" * 30)
    
    context_list = []
    
    for doc in results:
        meta = doc.metadata
        content = doc.page_content
        
        # == å®šä½é€»è¾‘ ==
        if meta["type"] == "image_frame":
            print(f"ğŸ”´ [æ‰¾åˆ°å›¾ç‰‡] å±äºæ¨¡å‹: {meta['scene_id']}")
            print(f"   å›¾ç‰‡è·¯å¾„: {meta['file_path']}")
            print(f"   ç”»é¢æè¿°: {content[:30]}...")
            context_list.append(f"å›¾ç‰‡(å±äº{meta['scene_id']}): {content}")
            
        elif meta["type"] == "model_summary":
            print(f"ğŸ”µ [æ‰¾åˆ°æ¨¡å‹] ID: {meta['scene_id']}")
            print(f"   æ¨¡å‹è·¯å¾„: {meta['file_path']}")
            print(f"   æ¨¡å‹æè¿°: {content[:30]}...")
            context_list.append(f"æ¨¡å‹æ•´ä½“ä¿¡æ¯: {content}")
            
    return context_list

# === æ ¸å¿ƒå‡½æ•° 4: å›½äº§ LLM å›ç­” ===
def chat_with_qwen(query, context_list):
    # ä½¿ç”¨ Qwen-Turbo æˆ– Qwen-Max
    llm = ChatTongyi(model_name="qwen-turbo") 
    
    context_str = "\n".join(context_list)
    prompt = f"""
    åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„å¤šæ¨¡æ€æ•°æ®ï¼ˆåŒ…å«æ¨¡å‹ä¿¡æ¯å’Œå›¾ç‰‡ç»†èŠ‚ï¼‰å›ç­”ç”¨æˆ·é—®é¢˜ï¼š
    {context_str}
    
    ç”¨æˆ·é—®é¢˜: {query}
    """
    
    response = llm.invoke(prompt)
    print("\nğŸ¤– Qwen å›ç­”:", response.content)

# === è¿è¡Œç¤ºä¾‹ ===
if __name__ == "__main__":
    # 1. åªæœ‰æ•°æ®å˜åŠ¨æ—¶è¿è¡Œ
    # docs = load_and_bind_data(DATA_DIR)
    # build_index(docs)
    
    # 2. æ£€ç´¢æµ‹è¯•
    # åœºæ™¯ï¼šæˆ‘æƒ³æ‰¾æŸä¸ªæ¨¡å‹çš„ä¿¯è§†å›¾
    search_results = search_engine("æœ‰æ²¡æœ‰æ­£ä¸Šæ–¹ä¿¯æ‹çš„è§†è§’ï¼Ÿ")
    chat_with_qwen("æœ‰æ²¡æœ‰æ­£ä¸Šæ–¹ä¿¯æ‹çš„è§†è§’ï¼Ÿ", search_results)