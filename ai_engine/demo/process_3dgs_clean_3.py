import subprocess
import sys
import shutil
import os
import time
from pathlib import Path
import json
import numpy as np
import logging

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.getLogger('nerfstudio').setLevel(logging.ERROR) 

# ================= ğŸ”§ ç”¨æˆ·é…ç½® (å…³é”®ä¿®æ”¹) =================
LINUX_WORK_ROOT = Path.home() / "braindance_workspace"
SCENE_RADIUS_SCALE = 1.8 

# ğŸ”¥ å¼ºåˆ¶å¼€å¯çƒä½“åˆ‡å‰²
FORCE_SPHERICAL_CULLING = True

# ğŸ”¥ åˆ‡å‰²åŠ›åº¦ (1.0 = æ ‡å‡†, 1.2 = å®½æ¾, 0.9 = æ¿€è¿›)
# å»ºè®®è®¾ä¸º 1.0 æˆ– 0.9ï¼Œè¿™æ ·ä¼šåˆ‡æ‰æ›´å¤šèƒŒæ™¯ã€‚
# å¦‚æœè®¾ä¸º 1.1ï¼Œè¡¨ç¤ºä¿ç•™åŠå¾„æ˜¯ç›¸æœºåœˆçš„ 1.1 å€ã€‚
CULLING_MULTIPLIER = 0.3 

# æ£€æŸ¥ä¾èµ–
try:
    from plyfile import PlyData, PlyElement
    HAS_PLYFILE = True
except ImportError:
    HAS_PLYFILE = False
    print("âŒ ä¸¥é‡è­¦å‘Š: æœªå®‰è£… plyfile åº“ï¼æ— æ³•æ‰§è¡Œåˆ‡å‰²ã€‚è¯·è¿è¡Œ: pip install plyfile")

# ================= æ ¸å¿ƒç®—æ³• 1: è®­ç»ƒå‚æ•°è®¡ç®— =================
def analyze_and_calculate_adaptive_collider(json_path):
    print(f"\nğŸ¤– [AI åˆ†æ] è§£æç›¸æœºè½¨è¿¹...")
    try:
        with open(json_path, 'r') as f: data = json.load(f)
        frames = data["frames"]
        if not frames: return [], "unknown"

        positions = []
        forward_vectors = []
        dists_to_origin = [] 
        
        for frame in frames:
            c2w = np.array(frame["transform_matrix"])
            positions.append(c2w[:3, 3])
            forward_vectors.append(c2w[:3, :3] @ np.array([0, 0, -1]))
            dists_to_origin.append(np.linalg.norm(c2w[:3, 3]))
            
        positions = np.array(positions)
        forward_vectors = np.array(forward_vectors)
        
        center = np.mean(positions, axis=0)
        vec_to_center = center - positions
        vec_to_center /= (np.linalg.norm(vec_to_center, axis=1, keepdims=True) + 1e-6)
        ratio = np.sum(np.sum(forward_vectors * vec_to_center, axis=1) > 0) / len(frames)
        
        print(f"    -> ç›¸æœºèšåˆåº¦: {ratio:.2f}")

        is_object_mode = ratio > 0.6 or FORCE_SPHERICAL_CULLING

        if is_object_mode:
            scene_type = "object"
            avg_dist = np.mean(dists_to_origin)
            min_dist = np.min(dists_to_origin)
            
            scene_radius = 1.0 * SCENE_RADIUS_SCALE
            calc_near = max(0.05, min_dist - scene_radius)
            calc_far = avg_dist + scene_radius
            
            print(f"    -> æ¨¡å¼: ç‰©ä½“ (Near={calc_near:.2f}, Far={calc_far:.2f})")
            return ["--pipeline.model.enable-collider", "True", 
                    "--pipeline.model.collider-params", "near_plane", str(round(calc_near, 2)), 
                    "far_plane", str(round(calc_far, 2))], "object"
        else:
            print(f"    -> æ¨¡å¼: åœºæ™¯ (ä¿ç•™å…¨æ™¯)")
            return ["--pipeline.model.enable-collider", "True", 
                    "--pipeline.model.collider-params", "near_plane", "0.05", "far_plane", "100.0"], "scene"

    except Exception as e:
        print(f"âš ï¸ åˆ†æå¤±è´¥ ({e})ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°ã€‚")
        return ["--pipeline.model.enable-collider", "True", 
                "--pipeline.model.collider-params", "near_plane", "0.1", "far_plane", "50.0"], "unknown"

# ================= æ ¸å¿ƒç®—æ³• 2: å¯¼å‡ºåçƒä½“åˆ‡å‰² (å‡çº§ç‰ˆ) =================
def perform_spherical_culling(ply_path, json_path, output_path):
    if not HAS_PLYFILE: 
        print("âŒ ç¼ºå°‘ plyfile åº“ï¼Œè·³è¿‡åˆ‡å‰²ã€‚")
        return False
        
    print(f"\nâœ‚ï¸ [åå¤„ç†] æ­£åœ¨æ‰§è¡Œã€æŠ—å¹²æ‰°ã€‘çƒä½“åˆ‡å‰²...")

    try:
        # 1. è®¡ç®—ä¿ç•™åŠå¾„ (ä½¿ç”¨åˆ†ä½æ•°æŠ—å¹²æ‰°)
        with open(json_path, 'r') as f: frames = json.load(f)["frames"]
        cam_pos = np.array([np.array(f["transform_matrix"])[:3, 3] for f in frames])
        
        center = np.mean(cam_pos, axis=0)
        dists = np.linalg.norm(cam_pos - center, axis=1)
        
        # === å…³é”®ä¿®æ”¹ï¼šä¸å†ä½¿ç”¨ maxï¼Œè€Œæ˜¯ä½¿ç”¨ 95% åˆ†ä½æ•° ===
        # è¿™æ„å‘³ç€æœ€è¿œçš„ 5% çš„ç›¸æœºï¼ˆå¯èƒ½æ˜¯é£˜å‡ºå»çš„è¯¯å·®ï¼‰ä¼šè¢«å¿½ç•¥ï¼Œä¸ä¼šæ’‘å¤§çƒä½“
        robust_max_radius = np.percentile(dists, 85)
        
        # è®¡ç®—æœ€ç»ˆä¿ç•™åŠå¾„
        keep_radius = robust_max_radius * CULLING_MULTIPLIER
        
        print(f"    -> å‡ ä½•ä¸­å¿ƒ: {center}")
        print(f"    -> æŠ—å¹²æ‰°åŠå¾„: {robust_max_radius:.2f} (æ’é™¤ç¦»ç¾¤ç›¸æœº)")
        print(f"    -> æœ€ç»ˆåˆ‡å‰²åŠå¾„: {keep_radius:.2f} (ç³»æ•° {CULLING_MULTIPLIER})")

        # 2. è¯»å–ç‚¹äº‘
        plydata = PlyData.read(str(ply_path))
        vertex = plydata['vertex']
        
        x, y, z = vertex['x'], vertex['y'], vertex['z']
        points = np.stack([x, y, z], axis=1)
        original_count = len(points)
        
        # 3. æ‰§è¡Œåˆ‡å‰²
        dists_pts = np.linalg.norm(points - center, axis=1)
        opacities = 1 / (1 + np.exp(-vertex['opacity']))
        
        # é€»è¾‘ï¼šè·ç¦» < åœˆå­ AND ç‚¹æ¯”è¾ƒå®
        mask = (dists_pts < keep_radius) & (opacities > 0.05)
        
        filtered_vertex = vertex[mask]
        new_count = len(filtered_vertex)
        
        print(f"    -> åŸå§‹ç‚¹æ•°: {original_count}")
        print(f"    -> å‰©ä½™ç‚¹æ•°: {new_count} (åˆ é™¤äº† {original_count - new_count} ä¸ªå™ªç‚¹)")
        
        # 4. ä¿å­˜
        PlyData([PlyElement.describe(filtered_vertex, 'vertex')]).write(str(output_path))
        return True

    except Exception as e:
        print(f"âŒ åˆ‡å‰²å¤±è´¥è¯¦æƒ…: {e}")
        return False

# ================= ä¸»æµç¨‹ =================

def run_pipeline(video_path, project_name):
    print(f"\nğŸš€ [BrainDance Engine V12] å¯åŠ¨ä»»åŠ¡: {project_name}")
    print(f"ğŸ”¥ åˆ‡å‰²åŠ›åº¦: {CULLING_MULTIPLIER} (è¶Šå°åˆ‡è¶Šç‹ )")
    
    video_src = Path(video_path).resolve()
    work_dir = LINUX_WORK_ROOT / project_name
    data_dir = work_dir / "data"
    output_dir = work_dir / "outputs"
    transforms_file = data_dir / "transforms.json"
    env = os.environ.copy()
    env["QT_QPA_PLATFORM"] = "offscreen" 

    # [Step 1] æ•°æ®å¤„ç†
    if transforms_file.exists():
        print(f"\nâ© [æ–­ç‚¹ç»­ä¼ ] æ£€æµ‹åˆ° COLMAP æ•°æ®")
    else:
        print(f"ğŸ†• [æ–°ä»»åŠ¡] åˆå§‹åŒ–...")
        if work_dir.exists(): shutil.rmtree(work_dir)
        work_dir.mkdir(parents=True)
        data_dir.mkdir(parents=True)
        shutil.copy(str(video_src), str(work_dir / video_src.name))

        print(f"\nğŸ¥ [1/3] COLMAP è§£ç®—")
        extracted_images_dir = data_dir / "images"
        extracted_images_dir.mkdir(parents=True, exist_ok=True)
        
        subprocess.run(["ffmpeg", "-y", "-i", str(work_dir / video_src.name), 
                        "-vf", "scale=1920:-1,fps=4", "-q:v", "2", 
                        str(extracted_images_dir / "frame_%05d.jpg")], check=True) 
        
        subprocess.run(
            ["ns-process-data", "images", "--data", str(extracted_images_dir), "--output-dir", str(data_dir), "--verbose"],
            check=True, env=env
        )

    # [Step 2] è®­ç»ƒ
    search_path = output_dir / project_name / "splatfacto"
    run_dirs = sorted(list(search_path.glob("*"))) if search_path.exists() else []
    
    scene_type_detected = "unknown"

    if run_dirs:
        print(f"\nâ© [è®­ç»ƒè·³è¿‡] å·²å®Œæˆ")
        _, scene_type_detected = analyze_and_calculate_adaptive_collider(transforms_file)
    else:
        collider_args, scene_type_detected = analyze_and_calculate_adaptive_collider(transforms_file)
        print(f"\nğŸ§  [2/3] å¼€å§‹è®­ç»ƒ...")
        subprocess.run([
            "ns-train", "splatfacto", "--data", str(data_dir), "--output-dir", str(output_dir), 
            "--experiment-name", project_name, "--pipeline.model.random-init", "False", 
            "--pipeline.model.cull-alpha-thresh", "0.005", *collider_args,
            "--max-num-iterations", "15000", "--vis", "viewer+tensorboard", 
            "--viewer.quit-on-train-completion", "True", "colmap"
        ], check=True, env=env)

    # [Step 3] å¯¼å‡º
    print(f"\nğŸ’¾ [3/3] å¯¼å‡ºç»“æœ")
    if not run_dirs: run_dirs = sorted(list(search_path.glob("*")))
    if not run_dirs: return None
    latest_run = run_dirs[-1]
    
    subprocess.run([
        "ns-export", "gaussian-splat", "--load-config", str(latest_run/"config.yml"), 
        "--output-dir", str(work_dir)
    ], check=True, env=env)
    time.sleep(5) 

    # [Step 3.5] å¼ºåˆ¶ç‰©ç†åˆ‡å‰²
    raw_ply = work_dir / "point_cloud.ply"
    if not raw_ply.exists(): raw_ply = work_dir / "splat.ply"

    cleaned_ply = work_dir / "point_cloud_cleaned.ply"
    final_ply_to_use = raw_ply

    should_clean = (scene_type_detected == "object") or FORCE_SPHERICAL_CULLING
    
    if should_clean:
        if raw_ply.exists():
            if perform_spherical_culling(raw_ply, transforms_file, cleaned_ply):
                print("âœ¨ æ¸…æ´—æˆåŠŸï¼")
                final_ply_to_use = cleaned_ply
        else:
            print(f"âŒ è­¦å‘Šï¼šæœªæ‰¾åˆ° PLY æ–‡ä»¶")
    else:
        print(f"â„¹ï¸ è·³è¿‡åˆ‡å‰²")

    # [Step 4] å›ä¼ 
    print(f"\nğŸ“¦ [IO åŒæ­¥] å›ä¼ è‡³ Windows...")
    target_dir = Path(__file__).parent / "results"
    target_dir.mkdir(exist_ok=True, parents=True) 
    
    transforms_src = data_dir / "transforms.json"
    final_webgl_poses = target_dir / "webgl_poses.json"
    final_ply_dst = target_dir / f"{project_name}.ply"
    
    if transforms_src.exists():
        try:
            with open(transforms_src, 'r') as f: d = json.load(f)
            frames = [{"file_path": fr["file_path"], "pose_matrix_c2w": np.array(fr["transform_matrix"], dtype=np.float32).tolist()} for fr in d["frames"]]
            with open(final_webgl_poses, 'w') as f: json.dump({"camera_model": d.get("camera_model","OPENCV"), "frames": frames}, f, indent=4)
        except: pass

    if final_ply_to_use and final_ply_to_use.exists():
        try:
            shutil.copy2(str(final_ply_to_use), str(final_ply_dst))
            if transforms_src.exists(): shutil.copy2(str(transforms_src), str(target_dir/"transforms.json"))
            shutil.rmtree(work_dir)
            print(f"âœ… å…¨éƒ¨å®Œæˆï¼: {final_ply_dst}")
            return str(final_ply_dst)
        except Exception as e:
            print(f"âŒ å›ä¼ å¤±è´¥: {e}")
            return None
    else:
        print("âŒ è‡´å‘½é”™è¯¯ï¼šå›ä¼ å¤±è´¥")
        return None

if __name__ == "__main__":
    script_dir = Path(__file__).resolve().parent
    video_file = script_dir / "test.mp4" 
    if len(sys.argv) > 1: video_file = Path(sys.argv[1])

    if video_file.exists():
        run_pipeline(video_file, "scene_auto_sync")
    else:
        print(f"âŒ æ‰¾ä¸åˆ°è§†é¢‘: {video_file}")