import os
import sys
import shutil
import time
import datetime
from pathlib import Path
import logging
import torch
from types import ModuleType
import numpy as np
from PIL import Image

# ================= ğŸ”¥ [RTX 5070 å…¼å®¹æ€§è¡¥ä¸ V32] ç»ˆæ Mock ğŸ”¥ =================
def inject_mocks():
    print("âš ï¸ [ç³»ç»Ÿæ£€æµ‹] æ­£åœ¨æ³¨å…¥ Kaolin å’Œ PyTorch3D çš„ V32 Mock æ¨¡å—...")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    class MockClass:
        def __init__(self, *args, **kwargs): self.device = device
        def __call__(self, *args, **kwargs): return torch.zeros(1, 3, device=device, requires_grad=True)
        def compose(self, *args, **kwargs): return self
        def inverse(self): return self
        def to(self, *args, **kwargs): return self
        def cpu(self): return self
        def cuda(self): return self
        def clone(self): return self
        def detach(self): return self
        def get_matrix(self): return torch.eye(4, device=device).unsqueeze(0)
        def transform_points(self, x): return x 
        def transform_normals(self, x): return x
        def __getattr__(self, name):
            def method_mock(*args, **kwargs): return self
            return method_mock
    
    def mock_func(*args, **kwargs): return torch.tensor(0.0, device=device)
    def mock_check_func(*args, **kwargs): return False 

    # --- Kaolin Mock ---
    if "kaolin" not in sys.modules:
        mock_kaolin = ModuleType("kaolin")
        submodules = ["ops", "ops.mesh", "ops.spc", "metrics", "metrics.pointcloud", "render", "render.camera", "render.mesh", "visualize", "io", "io.obj", "io.usd", "utils", "utils.testing"]
        for name in submodules:
            parts = name.split(".")
            parent = mock_kaolin
            for i, part in enumerate(parts):
                if not hasattr(parent, part):
                    new_mod = ModuleType(f"kaolin.{'.'.join(parts[:i+1])}")
                    setattr(parent, part, new_mod)
                    sys.modules[f"kaolin.{'.'.join(parts[:i+1])}"] = new_mod
                parent = getattr(parent, part)
        mock_kaolin.ops.mesh.TriangleHash = MockClass
        mock_kaolin.ops.mesh.check_sign = mock_func
        mock_kaolin.ops.mesh.sample_points = mock_func
        mock_kaolin.metrics.pointcloud.chamfer_distance = mock_func
        mock_kaolin.visualize.IpyTurntableVisualizer = MockClass
        mock_kaolin.render.camera.Camera = MockClass
        mock_kaolin.render.camera.CameraExtrinsics = MockClass
        mock_kaolin.render.camera.PinholeIntrinsics = MockClass
        mock_kaolin.render.mesh.dibr_rasterization = mock_func
        mock_kaolin.io.obj.import_mesh = lambda *args, **kwargs: (None, None)
        mock_kaolin.utils.testing.check_tensor = mock_func
        mock_kaolin.__path__ = []
        sys.modules["kaolin"] = mock_kaolin

    # --- PyTorch3D Mock ---
    if "pytorch3d" not in sys.modules:
        mock_p3d = ModuleType("pytorch3d")
        mock_p3d.__path__ = []
        mock_p3d.transforms = ModuleType("pytorch3d.transforms")
        mock_p3d.structures = ModuleType("pytorch3d.structures")
        mock_p3d.renderer = ModuleType("pytorch3d.renderer")
        mock_p3d.renderer.cameras = ModuleType("pytorch3d.renderer.cameras")
        mock_p3d.renderer.camera_utils = ModuleType("pytorch3d.renderer.camera_utils")
        mock_p3d.renderer.mesh = ModuleType("pytorch3d.renderer.mesh")
        mock_p3d.renderer.mesh.textures = ModuleType("pytorch3d.renderer.mesh.textures")
        mock_p3d.renderer.mesh.rasterizer = ModuleType("pytorch3d.renderer.mesh.rasterizer")
        mock_p3d.renderer.mesh.shader = ModuleType("pytorch3d.renderer.mesh.shader")
        sys.modules["pytorch3d.renderer.cameras"] = mock_p3d.renderer.cameras
        sys.modules["pytorch3d.renderer.camera_utils"] = mock_p3d.renderer.camera_utils
        sys.modules["pytorch3d.renderer.mesh"] = mock_p3d.renderer.mesh
        sys.modules["pytorch3d.renderer.mesh.textures"] = mock_p3d.renderer.mesh.textures
        sys.modules["pytorch3d.renderer.mesh.rasterizer"] = mock_p3d.renderer.mesh.rasterizer
        sys.modules["pytorch3d.renderer.mesh.shader"] = mock_p3d.renderer.mesh.shader
        mock_p3d.vis = ModuleType("pytorch3d.vis")
        mock_plotly_vis = ModuleType("pytorch3d.vis.plotly_vis")
        mock_plotly_vis.AxisArgs = MockClass
        mock_plotly_vis.Lighting = MockClass
        mock_plotly_vis.plot_scene = mock_func
        mock_plotly_vis.get_camera_wireframe = mock_func
        mock_plotly_vis._add_camera_trace = mock_func
        mock_plotly_vis._add_ray_bundle_trace = mock_func
        mock_plotly_vis._add_pointcloud_trace = mock_func
        mock_plotly_vis._add_mesh_trace = mock_func
        mock_plotly_vis._scale_camera_to_bounds = mock_func
        mock_plotly_vis._update_axes_bounds = mock_func
        mock_plotly_vis._is_ray_bundle = mock_check_func
        mock_plotly_vis._is_pointclouds = mock_check_func
        mock_plotly_vis._is_meshes = mock_check_func
        mock_plotly_vis._is_cameras = mock_check_func
        mock_p3d.vis.plotly_vis = mock_plotly_vis
        sys.modules["pytorch3d.vis"] = mock_p3d.vis
        sys.modules["pytorch3d.vis.plotly_vis"] = mock_plotly_vis
        mock_p3d.transforms.Transform3d = MockClass
        mock_p3d.transforms.Rotate = MockClass
        mock_p3d.transforms.Translate = MockClass
        mock_p3d.transforms.Scale = MockClass
        mock_p3d.transforms.quaternion_multiply = lambda q1, q2: q1 
        mock_p3d.transforms.quaternion_invert = lambda q: q
        mock_p3d.transforms.matrix_to_quaternion = lambda m: torch.tensor([1., 0., 0., 0.], device=m.device).repeat(m.shape[0], 1)
        mock_p3d.transforms.quaternion_to_matrix = lambda q: torch.eye(3, device=q.device).unsqueeze(0).repeat(q.shape[0], 1, 1)
        mock_p3d.transforms.axis_angle_to_quaternion = lambda a: torch.tensor([1., 0., 0., 0.], device=a.device).repeat(a.shape[0], 1)
        mock_p3d.transforms.quaternion_to_axis_angle = lambda q: torch.zeros((q.shape[0], 3), device=q.device)
        mock_p3d.transforms.axis_angle_to_matrix = lambda a: torch.eye(3, device=a.device).unsqueeze(0).repeat(a.shape[0], 1, 1)
        mock_p3d.renderer.look_at_view_transform = lambda **kwargs: (torch.eye(3, device=device).unsqueeze(0), torch.zeros(1, 3, device=device))
        mock_p3d.renderer.look_at_rotation = lambda **kwargs: torch.eye(3, device=device).unsqueeze(0)
        mock_p3d.renderer.camera_position_from_spherical_angles = lambda **kwargs: torch.zeros(1, 3, device=device)
        mock_p3d.renderer.ray_bundle_to_ray_points = lambda **kwargs: torch.zeros(1, 3, device=device)
        mock_p3d.renderer.ray_points_to_depth = lambda **kwargs: torch.zeros(1, device=device)
        mock_p3d.renderer.camera_utils.camera_to_eye_at_up = lambda **kwargs: (torch.zeros(1, 3, device=device), torch.zeros(1, 3, device=device), torch.zeros(1, 3, device=device))
        mock_p3d.renderer.camera_utils.join_cameras_as_batch = mock_func
        renderer_classes = ["FoVPerspectiveCameras", "PerspectiveCameras", "CamerasBase", "OrthographicCameras", "PointsRenderer", "PointsRasterizationSettings", "PointsRasterizer", "AlphaCompositor", "RasterizationSettings", "MeshRenderer", "MeshRasterizer", "MeshRendererWithFragments", "SoftPhongShader", "HardPhongShader", "SoftSilhouetteShader", "TexturesVertex", "TexturesAtlas", "TexturesUV", "PointLights", "DirectionalLights", "AmbientLights", "Materials", "BlendParams", "HeterogeneousRayBundle", "RayBundle", "ImplicitRenderer", "NDCGridRaysampler", "MonteCarloRaysampler"]
        for cls_name in renderer_classes:
            mock_cls = MockClass
            setattr(mock_p3d.renderer, cls_name, mock_cls)
            if "Cameras" in cls_name: setattr(mock_p3d.renderer.cameras, cls_name, mock_cls)
            if "Textures" in cls_name: setattr(mock_p3d.renderer.mesh.textures, cls_name, mock_cls)
            if "Shader" in cls_name: setattr(mock_p3d.renderer.mesh.shader, cls_name, mock_cls)
            if "Rasterizer" in cls_name and "Mesh" in cls_name: setattr(mock_p3d.renderer.mesh.rasterizer, cls_name, mock_cls)
        mock_p3d.structures.Meshes = MockClass
        mock_p3d.structures.Pointclouds = MockClass
        mock_p3d.structures.join_meshes_as_scene = mock_func
        mock_p3d.structures.join_meshes_as_batch = mock_func
        mock_p3d.structures.list_to_padded = mock_func
        mock_p3d.structures.padded_to_list = mock_func
        sys.modules["pytorch3d"] = mock_p3d
        sys.modules["pytorch3d.transforms"] = mock_p3d.transforms
        sys.modules["pytorch3d.structures"] = mock_p3d.structures
        sys.modules["pytorch3d.renderer"] = mock_p3d.renderer
    print("âœ… [Mock V32] æ³¨å…¥å®Œæˆ")

# æ³¨å…¥ Mocks
inject_mocks()

# ================= ğŸ”§ é…ç½®åŒºåŸŸ =================
INPUT_IMAGE_NAME = "input.jpg"  # è„šæœ¬ä¼šè‡ªåŠ¨ä¼˜å…ˆæŸ¥æ‰¾ input.png
LINUX_WORK_ROOT = Path.home() / "sam3d_workspace"
SAM3D_REPO_PATH = Path.home() / "workspace/ai/sam-3d-objects"
CONFIG_PATH = SAM3D_REPO_PATH / "checkpoints/hf/pipeline.yaml"

# ğŸ”¥ğŸ”¥ [ä¿®å¤ç‚¹] CPU é…ç½®ä¿å­˜è·¯å¾„æ”¹ä¸ºä¸ CONFIG_PATH åŒçº§ç›®å½• ğŸ”¥ğŸ”¥
CPU_CONFIG_PATH = CONFIG_PATH.parent / "cpu_pipeline.yaml"

os.environ["TORCH_CUDA_ARCH_LIST"] = "9.0"

def format_duration(seconds):
    return str(datetime.timedelta(seconds=int(seconds)))

def setup_environment():
    if not SAM3D_REPO_PATH.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° SAM 3D ä»“åº“è·¯å¾„: {SAM3D_REPO_PATH}")
        sys.exit(1)
    
    sys.path.append(str(SAM3D_REPO_PATH))
    sys.path.append(str(SAM3D_REPO_PATH / "notebook"))
    os.chdir(SAM3D_REPO_PATH)

def prepare_cpu_config():
    """åˆ›å»ºä¸€ä¸ªå¼ºåˆ¶ä½¿ç”¨ CPU çš„ä¸´æ—¶é…ç½®æ–‡ä»¶"""
    print(f"ğŸ“ [Config Hack] æ­£åœ¨åˆ›å»º CPU åˆå§‹åŒ–é…ç½®: {CPU_CONFIG_PATH}")
    if not CONFIG_PATH.exists():
        print(f"âŒ æ‰¾ä¸åˆ°åŸå§‹é…ç½®: {CONFIG_PATH}")
        return False
    
    try:
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å¼ºåˆ¶æ›¿æ¢ device: cuda ä¸º device: cpu
        new_content = content.replace("device: cuda", "device: cpu")
        new_content = new_content.replace('device: "cuda"', 'device: "cpu"')
        
        # å†™å…¥åˆ° checkpoints/hf/cpu_pipeline.yaml
        with open(CPU_CONFIG_PATH, 'w', encoding='utf-8') as f:
            f.write(new_content)
            
        print(f"    âœ… å·²ç”Ÿæˆ CPU é…ç½®")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»º CPU é…ç½®å¤±è´¥: {e}")
        return False

def auto_generate_mask(image_np):
    """è‡ªåŠ¨ç”Ÿæˆ Mask (ç®€å•çš„å»ç™½/é»‘èƒŒæ™¯)"""
    # image_np æ˜¯ (H, W, 3) çš„ uint8
    
    # ç­–ç•¥1: äº®åº¦é˜ˆå€¼ (å»é™¤æ¥è¿‘ç™½è‰²çš„èƒŒæ™¯)
    # è®¡ç®—æ¯ä¸ªåƒç´ çš„äº®åº¦
    intensity = image_np.mean(axis=2)
    
    # å‡è®¾èƒŒæ™¯æ˜¯ç™½è‰²çš„ (äº®åº¦ > 240)
    is_white_bg = intensity > 240
    
    # å‡è®¾èƒŒæ™¯æ˜¯é»‘è‰²çš„ (äº®åº¦ < 15)
    is_black_bg = intensity < 15
    
    # ç”Ÿæˆ mask: èƒŒæ™¯éƒ¨åˆ†ä¸º 0ï¼Œç‰©ä½“éƒ¨åˆ†ä¸º 255
    # å¦‚æœå¤§éƒ¨åˆ†æ˜¯ç™½è‰²èƒŒæ™¯ï¼Œå°±å»é™¤ç™½è‰²ï¼›å¦‚æœæ˜¯é»‘è‰²ï¼Œå°±å»é™¤é»‘è‰²
    white_pixel_count = np.sum(is_white_bg)
    black_pixel_count = np.sum(is_black_bg)
    total_pixels = image_np.shape[0] * image_np.shape[1]
    
    if white_pixel_count > total_pixels * 0.1: # å¦‚æœæœ‰è¶…è¿‡10%çš„ç™½è‰²ï¼Œå‡è®¾æ˜¯ç™½èƒŒæ™¯
        print("    ğŸ¨ æ£€æµ‹åˆ°æµ…è‰²èƒŒæ™¯ï¼Œæ­£åœ¨è‡ªåŠ¨æŠ å›¾...")
        mask = np.where(is_white_bg, 0, 255).astype(np.uint8)
    elif black_pixel_count > total_pixels * 0.1: # å¦åˆ™å‡è®¾é»‘èƒŒæ™¯
        print("    ğŸ¨ æ£€æµ‹åˆ°æ·±è‰²èƒŒæ™¯ï¼Œæ­£åœ¨è‡ªåŠ¨æŠ å›¾...")
        mask = np.where(is_black_bg, 0, 255).astype(np.uint8)
    else:
        print("    âš ï¸ èƒŒæ™¯é¢œè‰²ä¸æ˜ç¡®ï¼Œä½¿ç”¨å…¨å›¾ Mask (å¯èƒ½ä¼šç”Ÿæˆæ–¹å—)")
        mask = np.ones((image_np.shape[0], image_np.shape[1]), dtype=np.uint8) * 255
        
    return mask

def run_pipeline():
    global_start_time = time.time()
    
    windows_dir = Path(__file__).resolve().parent
    source_img_path = windows_dir / INPUT_IMAGE_NAME
    # å°è¯•å¯»æ‰¾ png æ–‡ä»¶ (å¸¦é€æ˜é€šé“)
    source_png_path = windows_dir / "input.png"
    
    if source_png_path.exists():
        print(f"âœ¨ å‘ç° input.pngï¼Œå°†ä½¿ç”¨ Alpha é€šé“ä½œä¸º Mask (æ¨è)")
        source_img_path = source_png_path
        INPUT_EXT = ".png"
    else:
        INPUT_EXT = ".jpg"
    
    project_name = source_img_path.stem 
    work_dir = LINUX_WORK_ROOT / project_name
    
    print(f"\nğŸš€ [RTX 5070 Pipeline V44] å¯åŠ¨ä»»åŠ¡: {source_img_path.name}")
    
    if not source_img_path.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°å›¾ç‰‡ {source_img_path}")
        return

    if work_dir.exists(): shutil.rmtree(work_dir)
    work_dir.mkdir(parents=True, exist_ok=True)

    target_img_path = work_dir / source_img_path.name
    shutil.copy2(str(source_img_path), str(target_img_path))

    print(f"\nğŸ§  [2/3] åŠ è½½æ¨¡å‹æ¨ç† (å¼ºåˆ¶ CPU åˆå§‹åŒ–)...")
    setup_environment()
    
    if not prepare_cpu_config():
        return

    try:
        from inference import Inference, load_image
        import numpy as np
        from PIL import Image
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ ç»ˆææ‹¦æˆªå™¨ï¼šå¼ºåˆ¶ torch.load ä½¿ç”¨ CPU ğŸ”¥ğŸ”¥ğŸ”¥
        original_torch_load = torch.load
        def cpu_load_hook(*args, **kwargs):
            if 'map_location' not in kwargs:
                kwargs['map_location'] = 'cpu'
            return original_torch_load(*args, **kwargs)
        
        print("    ğŸ›¡ï¸ å·²æ¿€æ´»æ˜¾å­˜æ‹¦æˆªå™¨ï¼šå¼ºåˆ¶æ‰€æœ‰æƒé‡åŠ è½½è‡³ RAM...")
        torch.load = cpu_load_hook
        
        try:
            # åˆå§‹åŒ– (æ‰€æœ‰æ¨¡å‹è¿› RAM)
            inference = Inference(str(CPU_CONFIG_PATH))
            pipeline = inference._pipeline
            pipeline.device = torch.device('cuda') # æ¬ºéª— Pipeline
            print("    âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œæ˜¾å­˜å ç”¨ 0GB")
        finally:
            # æ¢å¤ torch.load
            torch.load = original_torch_load
            print("    ğŸ›¡ï¸ æ˜¾å­˜æ‹¦æˆªå™¨å·²è§£é™¤")

        # è¯»å–å¹¶å¤„ç†å›¾ç‰‡
        pil_image = Image.open(str(target_img_path)).convert("RGBA") # è¯»å– RGBA ä»¥é˜²ä¸‡ä¸€
        orig_w, orig_h = pil_image.size
        
        target_size = 512
        if max(orig_w, orig_h) > target_size:
            scale = target_size / max(orig_w, orig_h)
            new_w = int(orig_w * scale)
            new_h = int(orig_h * scale)
            pil_image = pil_image.resize((new_w, new_h), Image.LANCZOS)
            print(f"    ğŸ“‰ [æ˜¾å­˜ä¿æŠ¤] å›¾ç‰‡é™é‡‡æ ·è‡³: {new_w} x {new_h}")
        
        image_rgba = np.array(pil_image)
        image = image_rgba[:, :, :3] # å– RGB
        h, w = image.shape[:2]
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ æ™ºèƒ½ Mask ç”Ÿæˆ ğŸ”¥ğŸ”¥ğŸ”¥
        if INPUT_EXT == ".png" and image_rgba.shape[2] == 4:
            # å¦‚æœæ˜¯ PNG ä¸”æœ‰ Alpha é€šé“ï¼Œç›´æ¥ç”¨ Alpha ä½œä¸º Mask
            print("    ğŸ­ ä½¿ç”¨ PNG Alpha é€šé“ä½œä¸º Mask")
            mask = image_rgba[:, :, 3]
        else:
            # å¦‚æœæ˜¯ JPGï¼Œå°è¯•è‡ªåŠ¨å»é™¤èƒŒæ™¯
            mask = auto_generate_mask(image)
        
        # =========================================================
        # ğŸ”¥ ç¬¬ä¸€é˜¶æ®µï¼šæ¬è¿ Stage 1 æ¨¡å‹åˆ° GPU
        # =========================================================
        print("\nğŸšš [Stage 1] æ­£åœ¨å°† Stage 1 æ¨¡å‹æ¬è¿åˆ° GPU...")
        torch.cuda.empty_cache()
        
        pipeline.models["ss_generator"].to('cuda')
        pipeline.models["ss_decoder"].to('cuda')
        if "ss_encoder" in pipeline.models and pipeline.models["ss_encoder"] is not None:
            pipeline.models["ss_encoder"].to('cuda')
        
        if "ss_condition_embedder" in pipeline.condition_embedders:
            pipeline.condition_embedders["ss_condition_embedder"].to('cuda')
            
        print("ğŸš€ [Step 1/2] æ­£åœ¨è¿è¡Œ Stage 1 (ç”Ÿæˆç»“æ„)...")
        stage1_output = pipeline.run(
            image=image, 
            mask=mask, 
            stage1_only=True, 
            seed=42
        )
        print("    âœ… Stage 1 å®Œæˆï¼")

        # =========================================================
        # ğŸ”¥ ç¬¬äºŒé˜¶æ®µï¼šæ’¤å› Stage 1ï¼Œæ¬è¿ Stage 2
        # =========================================================
        print("\nğŸ”„ [æ˜¾å­˜åˆ‡æ¢] å¸è½½ Stage 1ï¼ŒåŠ è½½ Stage 2...")
        pipeline.models["ss_generator"].cpu()
        pipeline.models["ss_decoder"].cpu()
        if "ss_encoder" in pipeline.models and pipeline.models["ss_encoder"] is not None:
             pipeline.models["ss_encoder"].cpu()
        if "ss_condition_embedder" in pipeline.condition_embedders:
             pipeline.condition_embedders["ss_condition_embedder"].cpu()
        torch.cuda.empty_cache()
        
        pipeline.models["slat_generator"].to('cuda')
        pipeline.models["slat_decoder_gs"].to('cuda')
        if "slat_condition_embedder" in pipeline.condition_embedders:
            pipeline.condition_embedders["slat_condition_embedder"].to('cuda')
        
        print("    âœ… æ¨¡å‹åˆ‡æ¢å®Œæ¯•ï¼")
        pipeline.decode_formats = ["gaussian"]
        
        print("ğŸš€ [Step 2/2] æ­£åœ¨è¿è¡Œ Stage 2 (ç”Ÿæˆ Gaussian)...")
        original_sample_ss = pipeline.sample_sparse_structure
        pipeline.sample_sparse_structure = lambda *args, **kwargs: stage1_output
        
        try:
            output = pipeline.run(
                image=image,
                mask=mask,
                stage1_only=False, 
                seed=42,
                with_mesh_postprocess=False, 
                with_texture_baking=False 
            )
        finally:
            pipeline.sample_sparse_structure = original_sample_ss

        # ä¿å­˜ç»“æœ
        if "gs" in output:
            gaussian_splats = output["gs"]
            ply_output_path = work_dir / f"{project_name}_3d.ply"
            gaussian_splats.save_ply(str(ply_output_path))
            print(f"    âœ… ç”ŸæˆæˆåŠŸ: {ply_output_path.name}")
        else:
            print("    âŒ é”™è¯¯: è¾“å‡ºä¸­æ²¡æœ‰ Gaussian Splats æ•°æ®")
            return
        
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        torch.cuda.empty_cache()
        return

    final_windows_path = windows_dir / f"{project_name}_3dgs.ply"
    if ply_output_path.exists():
        shutil.copy2(str(ply_output_path), str(final_windows_path))
        print(f"\nğŸ‰ æˆåŠŸï¼æ¨¡å‹å·²ä¿å­˜: {final_windows_path}")
    else:
        print("    âŒ å¤±è´¥: æœªç”Ÿæˆ PLY æ–‡ä»¶")

    print(f"\nğŸ“Š æ€»è€—æ—¶: {format_duration(time.time() - global_start_time)}")

if __name__ == "__main__":
    run_pipeline()