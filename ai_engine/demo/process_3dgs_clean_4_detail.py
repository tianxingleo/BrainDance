import subprocess # å¼•å…¥å­è¿›ç¨‹ç®¡ç†åº“ï¼šç”¨äºåœ¨Pythonè„šæœ¬ä¸­æ‰§è¡Œå¤–éƒ¨ç³»ç»Ÿå‘½ä»¤ï¼ˆå¦‚ ffmpeg, colmap, ns-train ç­‰ CLI å·¥å…·ï¼‰
import sys # å¼•å…¥ç³»ç»Ÿç›¸å…³åº“ï¼šç”¨äºè·å–å‘½ä»¤è¡Œå‚æ•° (sys.argv) å’Œç®¡ç† Python è·¯å¾„
import shutil # å¼•å…¥é«˜çº§æ–‡ä»¶æ“ä½œåº“ï¼šç”¨äºå¤åˆ¶æ–‡ä»¶ (copy), ç§»åŠ¨æ–‡ä»¶ (move), åˆ é™¤ç›®å½•æ ‘ (rmtree) ä»¥åŠæŸ¥æ‰¾å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„ (which)
import os # å¼•å…¥æ“ä½œç³»ç»Ÿæ¥å£åº“ï¼šç”¨äºç¯å¢ƒå˜é‡è®¾ç½®, è·¯å¾„æ‹¼æ¥, æ–‡ä»¶çŠ¶æ€æ£€æµ‹ç­‰
import time # å¼•å…¥æ—¶é—´åº“ï¼šç”¨äºè®¡ç®—ç¨‹åºè¿è¡Œè€—æ—¶ (time.time()) å’Œ çº¿ç¨‹ä¼‘çœ  (time.sleep)
import datetime # å¼•å…¥æ—¥æœŸæ—¶é—´åº“ï¼šç”¨äºå°†ç§’æ•°æ ¼å¼åŒ–ä¸ºäººç±»å¯è¯»çš„æ—¶é—´æ ¼å¼ (HH:MM:SS)
from pathlib import Path # å¼•å…¥é¢å‘å¯¹è±¡çš„æ–‡ä»¶è·¯å¾„å¤„ç†åº“ï¼šæ¯” os.path æ›´ç›´è§‚ï¼Œç”¨äºè·¨å¹³å°è·¯å¾„æ“ä½œ
import json # å¼•å…¥JSONå¤„ç†åº“ï¼šç”¨äºè¯»å–å’Œå†™å…¥ç›¸æœºå§¿æ€æ–‡ä»¶ (transforms.json)
import numpy as np # å¼•å…¥æ•°å€¼è®¡ç®—åº“ï¼šç”¨äºçŸ©é˜µè¿ç®—ã€å‘é‡è®¡ç®—ã€ç»Ÿè®¡åˆ†æï¼ˆå¦‚è®¡ç®—åˆ†ä½æ•°ã€å‡å€¼ç­‰ï¼‰ï¼Œæ˜¯ç§‘å­¦è®¡ç®—çš„æ ¸å¿ƒ
import logging # å¼•å…¥æ—¥å¿—åº“ï¼šç”¨äºæ§åˆ¶ç¬¬ä¸‰æ–¹åº“ï¼ˆå¦‚ nerfstudioï¼‰çš„æ—¥å¿—è¾“å‡ºçº§åˆ«
import cv2 # å¼•å…¥OpenCVåº“ (è®¡ç®—æœºè§†è§‰åº“)ï¼šç”¨äºè¯»å–å›¾ç‰‡ã€å›¾åƒç°åº¦åŒ–ã€è®¡ç®—æ‹‰æ™®æ‹‰æ–¯æ¢¯åº¦ï¼ˆæ¨¡ç³Šæ£€æµ‹ï¼‰ã€è§†é¢‘æŠ½å¸§ç­‰
import re # å¼•å…¥æ­£åˆ™è¡¨è¾¾å¼åº“ï¼šç”¨äºä» COLMAP çš„æ—¥å¿—æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯ï¼ˆå¦‚åŒ¹é…ç‡ç™¾åˆ†æ¯”ï¼‰

import os # (é‡å¤å¯¼å…¥ï¼Œæ— å½±å“)
# è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¼ºåˆ¶ setuptools ä½¿ç”¨æ ‡å‡†åº“çš„ distutilsã€‚
# è¿™æ˜¯ä¸ºäº†è§£å†³é«˜ç‰ˆæœ¬ Python (3.10+) ä¸­ setuptools å’Œ distutils çš„å…¼å®¹æ€§è­¦å‘Šæˆ–æŠ¥é”™é—®é¢˜ã€‚
os.environ["SETUPTOOLS_USE_DISTUTILS"] = "stdlib"

import torch # å¼•å…¥ PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼šNerfstudio çš„åº•å±‚å¼•æ“
# è®¾ç½®çŸ©é˜µä¹˜æ³•çš„ç²¾åº¦ä¸º 'high' (ç›¸å½“äºå¼€å¯ TF32 - TensorFloat-32)ã€‚
# åŠŸèƒ½ï¼šåœ¨ NVIDIA Ampere æ¶æ„åŠä»¥åçš„æ˜¾å¡ä¸Šï¼Œèƒ½æ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒè¶³å¤Ÿçš„ç²¾åº¦ã€‚
torch.set_float32_matmul_precision('high') 

# ğŸ”¥ã€ç»æ€ã€‘å¼ºåˆ¶å°†ç¼–è¯‘å¥½çš„ç³»ç»Ÿçº§ colmap è·¯å¾„æåˆ°æœ€å‰é¢
# èƒŒæ™¯ï¼šConda ç¯å¢ƒä¸­å¸¸è‡ªå¸¦ä¸€ä¸ªé˜‰å‰²ç‰ˆæˆ–æ—§ç‰ˆçš„ colmapï¼Œä¼šå¯¼è‡´åŠŸèƒ½ç¼ºå¤±ã€‚
# é€»è¾‘ï¼šå¼ºåˆ¶å°†ç³»ç»Ÿé»˜è®¤è·¯å¾„ (/usr/local/bin) æ’å…¥åˆ° PATH ç¯å¢ƒå˜é‡çš„æœ€å‰é¢ã€‚
sys_path = "/usr/local/bin" # å®šä¹‰ç³»ç»Ÿçº§äºŒè¿›åˆ¶æ–‡ä»¶ç›®å½•
current_path = os.environ.get("PATH", "") # è·å–å½“å‰çš„ç¯å¢ƒå˜é‡ PATH

# åˆ¤æ–­ sys_path æ˜¯å¦å·²ç»åœ¨ PATH çš„ç¬¬ä¸€ä¸ªä½ç½® (ç”¨ os.pathsep åˆ†å‰²ï¼ŒLinuxä¸‹æ˜¯å†’å·)
if sys_path not in current_path.split(os.pathsep)[0]: 
    print(f"âš¡ [ç¯å¢ƒä¿®æ­£] å¼ºåˆ¶è®¾ç½® PATH ä¼˜å…ˆçº§: {sys_path} -> Priority High")
    # å°† sys_path æ‹¼æ¥åˆ°æœ€å‰é¢ï¼Œè¦†ç›–æ‰ Conda æˆ–å…¶ä»–ç¯å¢ƒä¸­çš„åŒåå·¥å…·
    os.environ["PATH"] = f"{sys_path}{os.pathsep}{current_path}"

# éªŒè¯ä¸€ä¸‹ colmap çš„è·¯å¾„
import shutil # (é‡å¤å¯¼å…¥ï¼Œæ— å½±å“)
colmap_loc = shutil.which("colmap") # æŸ¥æ‰¾å½“å‰ç¯å¢ƒä¸‹ 'colmap' å‘½ä»¤çš„å…·ä½“è·¯å¾„
print(f"ğŸ§ [è‡ªæ£€] å½“å‰è„šæœ¬ä½¿ç”¨çš„ COLMAP è·¯å¾„: {colmap_loc}") # æ‰“å°è·¯å¾„ä¾›ç”¨æˆ·æ ¸å¯¹

# è®¾ç½®æ—¥å¿—çº§åˆ«
# åŠŸèƒ½ï¼šå±è”½ Nerfstudio çš„ INFO/WARNING çº§åˆ«æ—¥å¿—ï¼Œåªæ˜¾ç¤º ERRORï¼Œè®©æ§åˆ¶å°è¾“å‡ºæ›´æ¸…çˆ½ã€‚
logging.getLogger('nerfstudio').setLevel(logging.ERROR) 

# ================= ğŸ”§ ç”¨æˆ·é…ç½® (æš´åŠ›è£å‰ªç‰ˆ) =================
# å®šä¹‰å·¥ä½œæ ¹ç›®å½•ï¼šåœ¨å½“å‰ç”¨æˆ·çš„ä¸»ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªåä¸º "braindance_workspace" çš„æ–‡ä»¶å¤¹
LINUX_WORK_ROOT = Path.home() / "braindance_workspace"
# åœºæ™¯åŠå¾„ç¼©æ”¾æ¯”ä¾‹ï¼šç”¨äº adaptive_collider è®¡ç®—ï¼Œå†³å®šè®­ç»ƒæ—¶çš„è¿‘å¹³é¢å’Œè¿œå¹³é¢èŒƒå›´ã€‚1.8 è¡¨ç¤ºåœ¨è®¡ç®—å‡ºçš„ç‰©ä½“åŠå¾„åŸºç¡€ä¸Šæ‰©å¤§ 1.8 å€ã€‚
SCENE_RADIUS_SCALE = 1.8 
# ğŸ”¥ å…¨å±€æœ€å¤§å›¾ç‰‡æ•°é‡é™åˆ¶ï¼šä¸ºäº†é˜²æ­¢æ˜¾å­˜çˆ†ç‚¸æˆ–è®­ç»ƒæ—¶é—´è¿‡é•¿ï¼Œé™åˆ¶é€å…¥ COLMAP çš„å›¾ç‰‡ä¸è¶…è¿‡ 200 å¼ ã€‚
MAX_IMAGES = 200 

# ================= è¾…åŠ©å·¥å…·ï¼šæ—¶é—´æ ¼å¼åŒ– =================
def format_duration(seconds):
    """
    åŠŸèƒ½ï¼šå°†æµ®ç‚¹æ•°ç§’æ•°è½¬æ¢ä¸º HH:MM:SS æ ¼å¼çš„å­—ç¬¦ä¸²ã€‚
    å‚æ•° seconds: è€—æ—¶ç§’æ•° (float)ã€‚
    """
    return str(datetime.timedelta(seconds=int(seconds)))

# ================= è¾…åŠ©å·¥å…·ï¼šæ¨¡ç³Šå›¾ç‰‡è¿‡æ»¤ =================
def smart_filter_blurry_images(image_folder, keep_ratio=0.85, max_images=MAX_IMAGES):
    """
    å‡çº§ç‰ˆæ¸…æ´—è„šæœ¬ï¼šæ··åˆç­–ç•¥ (Hybrid Strategy)
    è¯¥å‡½æ•°å®ç°äº†ä¸€å¥—å¤æ‚çš„å›¾ç‰‡ç­›é€‰é€»è¾‘ï¼ŒåŒ…å«è´¨é‡è¯„ä¼°å’Œå‡åŒ€é‡‡æ ·ã€‚
    
    å‚æ•°:
        image_folder: å›¾ç‰‡æ‰€åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        keep_ratio: è´¨é‡ä¿ç•™æ¯”ä¾‹ï¼Œ0.85 è¡¨ç¤ºå‰”é™¤æœ€å·®çš„ 15%ã€‚
        max_images: æœ€ç»ˆä¿ç•™çš„æœ€å¤§å›¾ç‰‡æ•°é‡ã€‚
    """
    print(f"\nğŸ§  [æ™ºèƒ½æ¸…æ´—] æ­£åœ¨åˆ†æå›¾ç‰‡è´¨é‡ (æ··åˆç­–ç•¥ç‰ˆ)...")
    
    image_dir = Path(image_folder) # å°†è·¯å¾„å­—ç¬¦ä¸²è½¬æ¢ä¸º Path å¯¹è±¡
    # è·å–ç›®å½•ä¸‹æ‰€æœ‰ jpg, jpeg, png åç¼€çš„æ–‡ä»¶ï¼Œå¹¶æ’åº
    images = sorted([p for p in image_dir.iterdir() if p.suffix.lower() in ['.jpg', '.jpeg', '.png']])
    
    if not images: # å¦‚æœåˆ—è¡¨ä¸ºç©º
        print("âŒ æ²¡æ‰¾åˆ°å›¾ç‰‡")
        return

    # åˆ›å»ºä¸€ä¸ªå­˜æ”¾åºŸå¼ƒå›¾ç‰‡çš„ç›®å½• "trash_smart"ï¼Œä½äºå›¾ç‰‡ç›®å½•çš„ä¸Šçº§ç›®å½•ä¸­
    trash_dir = image_dir.parent / "trash_smart"
    trash_dir.mkdir(exist_ok=True) # åˆ›å»ºç›®å½•ï¼Œå¦‚æœå­˜åœ¨åˆ™ä¸æŠ¥é”™

    img_scores = [] # ç”¨äºå­˜å‚¨ (å›¾ç‰‡è·¯å¾„, æ¸…æ™°åº¦åˆ†æ•°) çš„åˆ—è¡¨

    # --- ç¬¬ä¸€æ­¥ï¼šè®¡ç®—åˆ†æ•° (Laplacian Variance) ---
    # éå†æ¯ä¸€å¼ å›¾ç‰‡è¿›è¡Œè¯„åˆ†
    for i, img_path in enumerate(images):
        img = cv2.imread(str(img_path)) # ä½¿ç”¨ OpenCV è¯»å–å›¾ç‰‡
        if img is None: continue # å¦‚æœè¯»å–å¤±è´¥ï¼ˆå¦‚æ–‡ä»¶æŸåï¼‰ï¼Œè·³è¿‡
        
        # å°†å›¾ç‰‡è½¬ä¸ºç°åº¦å›¾ï¼Œå› ä¸ºæ¸…æ™°åº¦æ£€æµ‹ä¸»è¦çœ‹æ¢¯åº¦ï¼Œä¸éœ€è¦é¢œè‰²ä¿¡æ¯
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        h, w = gray.shape # è·å–å›¾ç‰‡çš„é«˜åº¦å’Œå®½åº¦

        # ç®—æ³•é€»è¾‘ï¼šä¹å®«æ ¼è¯„åˆ†æ³•
        # ä¸ºäº†é¿å…èƒŒæ™¯è™šåŒ–å¯¼è‡´æ•´å¼ å›¾åˆ†æ•°ä½ï¼Œæˆ‘ä»¬å°†å›¾ç‰‡åˆ‡æˆ 3x3 çš„æ ¼å­ï¼Œå–æœ€æ¸…æ™°çš„é‚£ä¸ªæ ¼å­ä½œä¸ºæ•´å¼ å›¾çš„åˆ†æ•°ã€‚
        grid_h, grid_w = h // 3, w // 3 # è®¡ç®—æ¯ä¸ªæ ¼å­çš„å°ºå¯¸
        max_grid_score = 0 # åˆå§‹åŒ–å½“å‰å›¾ç‰‡çš„æœ€å¤§åˆ†æ•°ä¸º 0
        
        # åŒé‡å¾ªç¯éå† 3x3 ç½‘æ ¼
        for r in range(3):
            for c in range(3):
                # åˆ‡ç‰‡æ“ä½œï¼Œæå–å½“å‰æ ¼å­çš„å›¾åƒåŒºåŸŸ (Region of Interest)
                roi = gray[r*grid_h:(r+1)*grid_h, c*grid_w:(c+1)*grid_w]
                # æ ¸å¿ƒç®—æ³•ï¼šä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­è®¡ç®—å›¾åƒçš„äºŒé˜¶å¯¼æ•°ï¼Œå¹¶æ±‚æ–¹å·®ã€‚
                # æ–¹å·®è¶Šå¤§ï¼Œè¯´æ˜è¾¹ç¼˜è¶Šé”åˆ©ï¼Œå›¾ç‰‡è¶Šæ¸…æ™°ã€‚
                score = cv2.Laplacian(roi, cv2.CV_64F).var()
                if score > max_grid_score:
                    max_grid_score = score # æ›´æ–°æœ€å¤§åˆ†æ•°
        
        # å°†ç»“æœå­˜å…¥åˆ—è¡¨
        img_scores.append((img_path, max_grid_score))
        # æ¯å¤„ç† 20 å¼ æ‰“å°ä¸€æ¬¡è¿›åº¦
        if i % 20 == 0:
            print(f"  -> åˆ†æä¸­... {img_path.name}: å±€éƒ¨æœ€é«˜åˆ† {max_grid_score:.1f}")

    # --- ç¬¬äºŒæ­¥ï¼šè´¨é‡æ¸…æ´— (å‰”é™¤åºŸç‰‡) ---
    # æå–æ‰€æœ‰çš„åˆ†æ•°ç»„æˆä¸€ä¸ªåˆ—è¡¨
    scores = [s[1] for s in img_scores]
    if not scores: return

    num_total = len(scores)
    # ä½¿ç”¨ numpy è®¡ç®—ç™¾åˆ†ä½æ•°é˜ˆå€¼ã€‚
    # ä¾‹å¦‚ keep_ratio=0.85ï¼Œæˆ‘ä»¬è¦å‰”é™¤åº•éƒ¨ 15% çš„åˆ†æ•°ã€‚
    # np.percentile è®¡ç®—å‡ºç¬¬ 15% ä½ç½®çš„åˆ†æ•°å€¼ï¼Œä½äºè¿™ä¸ªåˆ†æ•°çš„éƒ½å°†è¢«å‰”é™¤ã€‚
    quality_threshold = np.percentile(scores, (1 - keep_ratio) * 100)
    
    print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print(f"   - å›¾ç‰‡æ€»æ•°: {num_total}")
    print(f"   - è´¨é‡é˜ˆå€¼ (Bottom {(1-keep_ratio)*100:.0f}%): {quality_threshold:.2f}")

    good_images = [] # æš‚å­˜åˆæ ¼çš„å›¾ç‰‡ (è·¯å¾„)
    removed_count_quality = 0 # è®°å½•å› è´¨é‡å·®è¢«ç§»é™¤çš„æ•°é‡

    # éå†æ‰€æœ‰å›¾ç‰‡åŠå…¶åˆ†æ•°ï¼Œè¿›è¡Œç­›é€‰
    for img_path, score in img_scores:
        if score < quality_threshold:
            # å¦‚æœåˆ†æ•°ä½äºé˜ˆå€¼ï¼Œç§»åŠ¨åˆ°åƒåœ¾æ¡¶ç›®å½•
            # shutil.move å®ç°æ–‡ä»¶ç§»åŠ¨æ“ä½œ
            shutil.move(str(img_path), str(trash_dir / img_path.name))
            removed_count_quality += 1
        else:
            good_images.append(img_path) # è´¨é‡åˆæ ¼ï¼Œæš‚æ—¶ä¿ç•™

    print(f"   -> ç¬¬ä¸€è½®æ¸…æ´—å®Œæˆ: å‰”é™¤ {removed_count_quality} å¼ åºŸç‰‡ï¼Œå‰©ä½™ {len(good_images)} å¼ åˆæ ¼å›¾ç‰‡ã€‚")

    # --- ç¬¬ä¸‰æ­¥ï¼šæ•°é‡æ§åˆ¶ (å‡åŒ€é‡‡æ ·) ---
    removed_count_quantity = 0 # è®°å½•å› è¶…å‡ºæ•°é‡é™åˆ¶è¢«ç§»é™¤çš„æ•°é‡
    
    # å¦‚æœåˆæ ¼çš„å›¾ç‰‡æ•°é‡ä¾ç„¶è¶…è¿‡å…¨å±€æœ€å¤§é™åˆ¶ (MAX_IMAGES)
    if len(good_images) > max_images:
        print(f"   âš ï¸ åˆæ ¼å›¾ç‰‡ ({len(good_images)}) ä»è¶…è¿‡ä¸Šé™ ({max_images})")
        print(f"   -> æ‰§è¡Œã€å‡åŒ€é‡‡æ ·ã€‘ä»¥ä¿è¯è§†è§’è¦†ç›–...")
        
        # ç®—æ³•é€»è¾‘ï¼šå‡åŒ€é‡‡æ · (Uniform Sampling)
        # np.linspace åœ¨ [0, len-1] åŒºé—´å†…å‡åŒ€ç”Ÿæˆ max_images ä¸ªæ•°å­—ã€‚
        # ä½œç”¨ï¼šç¡®ä¿ä¿ç•™çš„å›¾ç‰‡åœ¨æ—¶é—´è½´/ç©ºé—´è½´ä¸Šæ˜¯åˆ†å¸ƒå‡åŒ€çš„ï¼Œè€Œä¸æ˜¯åªä¿ç•™å‰200å¼ ã€‚
        indices_to_keep = set(np.linspace(0, len(good_images) - 1, max_images, dtype=int))
        
        # éå†å½“å‰æ‰€æœ‰åˆæ ¼å›¾ç‰‡
        for idx, img_path in enumerate(good_images):
            if idx not in indices_to_keep: # å¦‚æœç´¢å¼•ä¸åœ¨ä¿ç•™åˆ—è¡¨ä¸­
                # è™½ç„¶è´¨é‡åˆæ ¼ï¼Œä½†ä¸ºäº†æ•°é‡é™åˆ¶ä¸å¾—ä¸åˆ 
                shutil.move(str(img_path), str(trash_dir / img_path.name))
                removed_count_quantity += 1
    else:
        print(f"   âœ… åˆæ ¼å›¾ç‰‡æ•°é‡ ({len(good_images)}) æœªè¶…æ ‡ï¼Œå…¨éƒ¨ä¿ç•™ã€‚")

    # ç»Ÿè®¡æœ€ç»ˆç»“æœ
    total_removed = removed_count_quality + removed_count_quantity
    final_count = num_total - total_removed
    print(f"âœ¨ æ¸…æ´—ç»“æŸ: å…±ç§»é™¤ {total_removed} å¼  (åºŸç‰‡ {removed_count_quality} + é‡‡æ · {removed_count_quantity})ï¼Œæœ€ç»ˆä¿ç•™ {final_count} å¼ ã€‚")

# ğŸ”¥ å¼ºåˆ¶å¼€å¯çƒä½“åˆ‡å‰²é…ç½®
# å¦‚æœè®¾ä¸º Trueï¼Œæ— è®ºåœºæ™¯è¢«åˆ¤æ–­ä¸ºä»€ä¹ˆç±»å‹ï¼Œéƒ½ä¼šåœ¨æœ€åæ‰§è¡Œç‚¹äº‘åˆ‡å‰²ã€‚
FORCE_SPHERICAL_CULLING = True

# ğŸ”¥ æ ¸å¿ƒå‚æ•°ï¼šä¿ç•™ç™¾åˆ†æ¯” (0.0 ~ 1.0)
# ç”¨äºæœ€åçš„ç‚¹äº‘è£å‰ªç®—æ³•ã€‚
# 0.9 è¡¨ç¤ºè®¡ç®—æ‰€æœ‰ç‚¹åˆ°ä¸­å¿ƒçš„è·ç¦»ï¼Œåªä¿ç•™è·ç¦»æœ€è¿‘çš„ 90% çš„ç‚¹ï¼Œå»é™¤æœ€è¿œçš„ 10% (é€šå¸¸æ˜¯å¤©ç©ºæˆ–æè¿œå¤„çš„ä¼ªå½±)ã€‚
KEEP_PERCENTILE = 0.9

# æ£€æŸ¥ä¾èµ–ï¼šplyfile åº“
# plyfile ç”¨äºè¯»å†™ .ply æ ¼å¼çš„ 3D æ¨¡å‹æ–‡ä»¶ã€‚
try:
    from plyfile import PlyData, PlyElement
    HAS_PLYFILE = True # æ ‡è®°åº“å·²å®‰è£…
except ImportError:
    HAS_PLYFILE = False # æ ‡è®°åº“æœªå®‰è£…
    print("âŒ ä¸¥é‡è­¦å‘Š: æœªå®‰è£… plyfile åº“ï¼æ— æ³•æ‰§è¡Œåˆ‡å‰²ã€‚è¯·è¿è¡Œ: pip install plyfile")

# ================= æ ¸å¿ƒç®—æ³• 1: è®­ç»ƒå‚æ•°è®¡ç®— =================
def analyze_and_calculate_adaptive_collider(json_path):
    """
    åŠŸèƒ½ï¼šæ ¹æ®ç›¸æœºè½¨è¿¹ (transforms.json) åˆ†æåœºæ™¯ç±»å‹ï¼ˆæ˜¯ç‰©ä½“ Object è¿˜æ˜¯åœºæ™¯ Sceneï¼‰ï¼Œ
    å¹¶è®¡ç®—åŠ¨æ€çš„ collider å‚æ•° (near/far planes)ï¼Œä»¥ä¼˜åŒ– NeRF/Splat è®­ç»ƒæ•ˆæœã€‚
    
    å‚æ•°: json_path: transforms.json æ–‡ä»¶çš„è·¯å¾„ã€‚
    è¿”å›: (å‚æ•°åˆ—è¡¨, åœºæ™¯ç±»å‹å­—ç¬¦ä¸²)
    """
    print(f"\nğŸ¤– [AI åˆ†æ] è§£æç›¸æœºè½¨è¿¹...")
    try:
        # è¯»å– json æ–‡ä»¶
        with open(json_path, 'r') as f: data = json.load(f)
        frames = data["frames"] # è·å–æ‰€æœ‰å¸§çš„ä¿¡æ¯
        if not frames: return [], "unknown" # å¦‚æœæ²¡å¸§ï¼Œè¿”å›æœªçŸ¥

        positions = [] # å­˜å‚¨ç›¸æœºä½ç½® (XYZ)
        forward_vectors = [] # å­˜å‚¨ç›¸æœºæœå‘å‘é‡
        dists_to_origin = [] # å­˜å‚¨ç›¸æœºåˆ°ä¸–ç•ŒåŸç‚¹çš„è·ç¦»
        
        for frame in frames:
            c2w = np.array(frame["transform_matrix"]) # è¯»å– 4x4 å˜æ¢çŸ©é˜µ (Camera-to-World)
            positions.append(c2w[:3, 3]) # æå–å¹³ç§»å‘é‡ (ç›¸æœºä½ç½®)
            # è®¡ç®—ç›¸æœºçš„å‰æ–¹å‘é‡ (å‡è®¾ OpenCV åæ ‡ç³»ï¼šZè½´å‘å†…ï¼Œæ‰€ä»¥ -Z æ˜¯å‰æ–¹)
            # çŸ©é˜µä¹˜æ³•ï¼šæ—‹è½¬çŸ©é˜µ @ [0,0,-1]
            forward_vectors.append(c2w[:3, :3] @ np.array([0, 0, -1]))
            # è®¡ç®—ä½ç½®åˆ°åŸç‚¹ (0,0,0) çš„æ¬§å‡ é‡Œå¾—è·ç¦»
            dists_to_origin.append(np.linalg.norm(c2w[:3, 3]))
            
        positions = np.array(positions) # è½¬ä¸º numpy æ•°ç»„
        forward_vectors = np.array(forward_vectors)
        
        # è®¡ç®—æ‰€æœ‰ç›¸æœºä½ç½®çš„å‡ ä½•ä¸­å¿ƒ (é‡å¿ƒ)
        center = np.mean(positions, axis=0)
        # è®¡ç®—ä»ç›¸æœºä½ç½®æŒ‡å‘ä¸­å¿ƒçš„å‘é‡
        vec_to_center = center - positions
        # å½’ä¸€åŒ–å‘é‡ (é™¤ä»¥æ¨¡é•¿)ï¼Œé˜²æ­¢é™¤ä»¥0åŠ äº†ä¸ª 1e-6
        vec_to_center /= (np.linalg.norm(vec_to_center, axis=1, keepdims=True) + 1e-6)
        
        # é€»è¾‘åˆ¤æ–­ï¼šè®¡ç®—â€œç›¸æœºæœå‘â€ä¸â€œæŒ‡å‘ä¸­å¿ƒå‘é‡â€çš„ç‚¹ç§¯ã€‚
        # ç‚¹ç§¯ > 0 è¡¨ç¤ºå¤¹è§’å°äº 90åº¦ï¼Œå³ç›¸æœºæ˜¯çœ‹ç€ä¸­å¿ƒçš„ã€‚
        # ç»Ÿè®¡çœ‹ç€ä¸­å¿ƒçš„ç›¸æœºçš„æ¯”ä¾‹ã€‚
        ratio = np.sum(np.sum(forward_vectors * vec_to_center, axis=1) > 0) / len(frames)
        
        print(f"    -> ç›¸æœºèšåˆåº¦: {ratio:.2f}")

        # å¦‚æœè¶…è¿‡ 60% çš„ç›¸æœºéƒ½çœ‹ç€ä¸­å¿ƒï¼Œæˆ–è€…å¼ºåˆ¶å¼€å¯äº†åˆ‡å‰²ï¼Œåˆ™è®¤ä¸ºæ˜¯â€œç‰©ä½“æ¨¡å¼â€(Object Mode)
        is_object_mode = ratio > 0.6 or FORCE_SPHERICAL_CULLING

        if is_object_mode:
            # ç‰©ä½“æ¨¡å¼ä¸‹çš„é€»è¾‘
            avg_dist = np.mean(dists_to_origin) # å¹³å‡æ‹æ‘„è·ç¦»
            min_dist = np.min(dists_to_origin) # æœ€è¿‘æ‹æ‘„è·ç¦»
            scene_radius = 1.0 * SCENE_RADIUS_SCALE # åœºæ™¯åŠå¾„
            
            # åŠ¨æ€è®¡ç®—è¿‘å¹³é¢ (near) å’Œè¿œå¹³é¢ (far)
            # near: é¿å…åˆ‡æ‰å¤ªè¿‘çš„ç‰©ä½“
            calc_near = max(0.05, min_dist - scene_radius)
            # far: æ¶µç›–å¹³å‡è·ç¦» + åŠå¾„
            calc_far = avg_dist + scene_radius
            
            # è¿”å› nerfstudio çš„è®­ç»ƒå‚æ•°
            return ["--pipeline.model.enable-collider", "True", 
                    "--pipeline.model.collider-params", "near_plane", str(round(calc_near, 2)), 
                    "far_plane", str(round(calc_far, 2))], "object"
        else:
            # åœºæ™¯æ¨¡å¼ (å¦‚èˆªæ‹ã€æ¼«æ¸¸)ï¼Œè®¾ç½®å¾ˆå¤§çš„è¿œå¹³é¢
            return ["--pipeline.model.enable-collider", "True", 
                    "--pipeline.model.collider-params", "near_plane", "0.05", "far_plane", "100.0"], "scene"

    except Exception as e:
        # å‡ºé”™æ—¶çš„é»˜è®¤å‚æ•°
        return ["--pipeline.model.enable-collider", "True", 
                "--pipeline.model.collider-params", "near_plane", "0.1", "far_plane", "50.0"], "unknown"

# ================= æ ¸å¿ƒç®—æ³• 2: åŸºäºåˆ†ä½æ•°çš„æš´åŠ›åˆ‡å‰² (New!) =================
def perform_percentile_culling(ply_path, json_path, output_path):
    """
    åŠŸèƒ½ï¼šå¯¹ç”Ÿæˆçš„ç‚¹äº‘è¿›è¡Œåå¤„ç†åˆ‡å‰²ã€‚
    é€»è¾‘ï¼šè®¡ç®—æ‰€æœ‰ç‚¹äº‘åˆ°ç›¸æœºè½¨è¿¹ä¸­å¿ƒçš„è·ç¦»ï¼Œä¿ç•™æœ€è¿‘çš„ X% (KEEP_PERCENTILE)ï¼Œåˆ é™¤è¿œå¤„çš„èƒŒæ™¯å™ªå£°ã€‚
    è¿™æ˜¯è§£å†³ 3DGS ç”Ÿæˆå¤§é‡æ¼‚æµ®èƒŒæ™¯å™ªç‚¹çš„æœ‰æ•ˆæ–¹æ³•ã€‚
    """
    if not HAS_PLYFILE: # æ£€æŸ¥ä¾èµ–
        print("âŒ ç¼ºå°‘ plyfile åº“ï¼Œè·³è¿‡åˆ‡å‰²ã€‚")
        return False
        
    print(f"\nâœ‚ï¸ [åå¤„ç†] æ­£åœ¨æ‰§è¡Œã€åˆ†ä½æ•°æš´åŠ›åˆ‡å‰²ã€‘...")
    print(f"ğŸ”¥ ç›®æ ‡: åªä¿ç•™ç¦»åœ†å¿ƒæœ€è¿‘çš„ {KEEP_PERCENTILE*100:.0f}% ç‚¹äº‘")

    try:
        # 1. è®¡ç®—åˆ‡å‰²ä¸­å¿ƒ
        # ä¾ç„¶ä½¿ç”¨ç›¸æœºä½ç½®çš„é‡å¿ƒä½œä¸ºçƒå¿ƒï¼Œå› ä¸ºå¯¹äºç»•ç‰©æ‹æ‘„ï¼Œç›¸æœºé‡å¿ƒé€šå¸¸å°±æ˜¯ç‰©ä½“ä¸­å¿ƒã€‚
        with open(json_path, 'r') as f: frames = json.load(f)["frames"]
        cam_pos = np.array([np.array(f["transform_matrix"])[:3, 3] for f in frames])
        center = np.mean(cam_pos, axis=0)
        
        print(f"    -> åˆ‡å‰²åœ†å¿ƒ (ç›¸æœºé‡å¿ƒ): {center}")

        # 2. è¯»å–åŸå§‹ PLY ç‚¹äº‘æ–‡ä»¶
        plydata = PlyData.read(str(ply_path))
        vertex = plydata['vertex'] # è·å–é¡¶ç‚¹æ•°æ®
        
        # æå– x, y, z åæ ‡
        x, y, z = vertex['x'], vertex['y'], vertex['z']
        # å †å æˆ (N, 3) çš„çŸ©é˜µ
        points = np.stack([x, y, z], axis=1)
        original_count = len(points)
        
        # 3. è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ä¸­å¿ƒçš„æ¬§å‡ é‡Œå¾—è·ç¦»
        print("    -> æ­£åœ¨è®¡ç®—æ‰€æœ‰ç‚¹çš„è·ç¦»åˆ†å¸ƒ...")
        dists_pts = np.linalg.norm(points - center, axis=1)
        
        # 4. === æ ¸å¿ƒé€»è¾‘ï¼šè®¡ç®—åˆ†ä½æ•°é˜ˆå€¼ ===
        # np.percentile æ‰¾åˆ°ä¸€ä¸ªè·ç¦»å€¼ Dï¼Œä½¿å¾—åªæœ‰ KEEP_PERCENTILE (å¦‚ 90%) çš„ç‚¹è·ç¦»å°äº Dã€‚
        threshold_radius = np.percentile(dists_pts, KEEP_PERCENTILE * 100)
        
        print(f"    -> ç»Ÿè®¡ç»“æœ: {KEEP_PERCENTILE*100:.0f}% çš„ç‚¹é›†ä¸­åœ¨åŠå¾„ {threshold_radius:.4f} ä»¥å†…")
        print(f"    -> æ‰§è¡Œåˆ‡å‰²: æ‰€æœ‰å¤§äº {threshold_radius:.4f} çš„ç‚¹å°†è¢«åˆ é™¤")
        
        # 5. æ‰§è¡Œåˆ‡å‰²
        # è·å–ç‚¹çš„ä¸é€æ˜åº¦ (opacity)ã€‚åœ¨ Gaussian Splatting ä¸­ï¼Œopacity é€šå¸¸ç»è¿‡ sigmoid æ¿€æ´»ï¼Œæ‰€ä»¥è¿™é‡Œç”¨ sigmoid è¿˜åŸä¸€ä¸‹ï¼ˆæˆ–è€…ç›´æ¥å–å€¼ï¼Œå–å†³äºå­˜å‚¨æ ¼å¼ï¼‰ã€‚
        # è¿™é‡Œä»£ç å†™çš„æ˜¯é€† Sigmoid çš„é€»è¾‘ï¼š1 / (1 + exp(-x))ï¼Œå…¶å®åº”è¯¥æ˜¯ ply é‡Œå­˜çš„æ˜¯ logitï¼Œè¿™é‡Œè½¬æˆæ¦‚ç‡ã€‚
        opacities = 1 / (1 + np.exp(-vertex['opacity']))
        
        # ç»„åˆè¿‡æ»¤æ¡ä»¶ (Mask)ï¼š
        # æ¡ä»¶1: è·ç¦» < é˜ˆå€¼ (ä¿ç•™è¿‘å¤„çš„ç‚¹)
        # æ¡ä»¶2: ä¸é€æ˜åº¦ > 0.05 (ä¿ç•™æ¯”è¾ƒå®ã€çœ‹å¾—è§çš„ç‚¹ï¼Œå‰”é™¤åŠé€æ˜å¹½çµç‚¹)
        mask = (dists_pts < threshold_radius) & (opacities > 0.05)
        
        # åº”ç”¨ Maskï¼Œåªä¿ç•™ç¬¦åˆæ¡ä»¶çš„é¡¶ç‚¹
        filtered_vertex = vertex[mask]
        new_count = len(filtered_vertex)
        
        print(f"    -> åŸå§‹ç‚¹æ•°: {original_count}")
        print(f"    -> å‰©ä½™ç‚¹æ•°: {new_count} (åˆ é™¤äº† {original_count - new_count} ä¸ªèƒŒæ™¯ç‚¹)")
        
        # 6. ä¿å­˜æ–°çš„ PLY æ–‡ä»¶
        # PlyElement.describe ç”¨äºåˆ›å»ºæ–°çš„ PLY å…ƒç´ ç»“æ„
        PlyData([PlyElement.describe(filtered_vertex, 'vertex')]).write(str(output_path))
        return True # è¿”å›æˆåŠŸ

    except Exception as e:
        print(f"âŒ åˆ‡å‰²å¤±è´¥è¯¦æƒ…: {e}")
        return False
    # ================= ä¸»æµç¨‹ =================

def run_pipeline(video_path, project_name):
    # --- å…¨å±€è®¡æ—¶å¼€å§‹ ---
    global_start_time = time.time()
    print(f"\nğŸš€ [BrainDance Engine V13] å¯åŠ¨ä»»åŠ¡: {project_name}")
    print(f"ğŸ•’ å¼€å§‹æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”ª åˆ‡å‰²ç­–ç•¥: ä¿ç•™ {KEEP_PERCENTILE*100}% æœ€è¿‘ç‚¹äº‘")
    
    video_src = Path(video_path).resolve()
    # å®šä¹‰æ ¸å¿ƒç›®å½•å˜é‡
    work_dir = LINUX_WORK_ROOT / project_name
    data_dir = work_dir / "data"
    output_dir = work_dir / "outputs"
    transforms_file = data_dir / "transforms.json"
    env = os.environ.copy()
    env["QT_QPA_PLATFORM"] = "offscreen" 

    # [Step 1] æ•°æ®å¤„ç†
    step1_start = time.time()
    
    print(f"ğŸ†• [å¼ºåˆ¶é‡ç½®] æ­£åœ¨åˆå§‹åŒ–å·¥ä½œç¯å¢ƒ...")
    if work_dir.exists(): 
        try:
            shutil.rmtree(work_dir)
        except Exception as e:
            print(f"âš ï¸ è­¦å‘Š: æ—§ç›®å½•æ¸…ç†å¤±è´¥ (å¯èƒ½è¢«å ç”¨): {e}")
    
    work_dir.mkdir(parents=True, exist_ok=True)
    data_dir.mkdir(parents=True, exist_ok=True)
    shutil.copy(str(video_src), str(work_dir / video_src.name))

    print(f"\nğŸ¥ [1/3] æ•°æ®å‡†å¤‡ (æ²™ç›’éš”ç¦»æ¨¡å¼)")
    
    # 1. å®šä¹‰ä¸¤ä¸ªéš”ç¦»åŒºåŸŸ
    # temp_dir: å­˜æ”¾ ffmpeg åŸå§‹äº§ç‰©ï¼Œå¯èƒ½åŒ…å«å‡ ç™¾å¼ å›¾
    temp_dir = work_dir / "temp_extract"
    temp_dir.mkdir(parents=True, exist_ok=True)
    
    # target_dir: æœ€ç»ˆé€ç»™ COLMAP çš„å¹²å‡€ç›®å½• (åªæ”¾ 200 å¼ )
    extracted_images_dir = work_dir / "raw_images"
    extracted_images_dir.mkdir(parents=True, exist_ok=True)
    
    # 2. FFmpeg æŠ½å¸§ (è¾“å‡ºåˆ°ä¸´æ—¶ç›®å½• temp_dir)
    print(f"    -> æ­£åœ¨æŠ½å¸§åˆ°ä¸´æ—¶ç›®å½•...")
    cap = cv2.VideoCapture(str(work_dir / video_src.name))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    cap.release()
    
    vf_param = "fps=4"
    if width > 1920:
        vf_param = "scale=1920:-1,fps=4"
        
    try:
        subprocess.run(["ffmpeg", "-y", "-i", str(work_dir / video_src.name), 
                        "-vf", vf_param, "-q:v", "2", 
                        str(temp_dir / "frame_%05d.jpg")], check=False) 
    except Exception as e:
        print(f"    âš ï¸ FFmpeg ç»“æŸ: {e}")
    
    # 3. åœ¨ä¸´æ—¶ç›®å½•è¿›è¡Œæ¸…æ´—
    smart_filter_blurry_images(temp_dir, keep_ratio=0.85)
    
    # 4. ã€å…³é”®æ­¥éª¤ã€‘ç™½åå•å¤åˆ¶ (ä» temp -> raw_images)
    print("    -> æ­£åœ¨æ‰§è¡Œã€æ•°é‡é™åˆ¶ä¸è¿ç§»ã€‘...")
    
    # è¯»å–æ‰€æœ‰åˆæ ¼å›¾ç‰‡
    all_candidates = sorted(list(temp_dir.glob("*.jpg")) + list(temp_dir.glob("*.png")))
    
    # æ¥ä¸Šæ–‡ï¼šall_candidates = sorted(list(temp_dir.glob("*.jpg")) + list(temp_dir.glob("*.png")))
    
    # 251 è¡Œå·¦å³ï¼šè·å–ä¸´æ—¶ç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡çš„æ€»æ•°
    total_candidates = len(all_candidates)
    # MAX_IMAGES = 200 # å…¨å±€å˜é‡ï¼Œä¹‹å‰å®šä¹‰è¿‡
    
    final_images_list = [] # ç”¨äºå­˜å‚¨æœ€ç»ˆå†³å®šé€å…¥ COLMAP çš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    
    # é€»è¾‘ï¼šå¦‚æœæ¸…æ´—åçš„å›¾ç‰‡æ•°é‡ä¾ç„¶è¶…è¿‡è®¾å®šçš„ä¸Šé™ (200å¼ )
    if total_candidates > MAX_IMAGES:
        print(f"    âš ï¸ å›¾ç‰‡è¿‡å¤š ({total_candidates}), æ­£åœ¨å‡åŒ€é€‰å– {MAX_IMAGES} å¼ ...")
        # ã€æ ¸å¿ƒç®—æ³•ã€‘å‡åŒ€é‡‡æ · (Uniform Sampling)
        # np.linspace(start, stop, num): åœ¨ 0 åˆ° æ€»æ•°-1 ä¹‹é—´ç”Ÿæˆ num ä¸ªå‡åŒ€åˆ†å¸ƒçš„æ•°å­—
        # ä¾‹å¦‚ï¼šä» 1000 å¼ é‡Œå– 200 å¼ ï¼Œå®ƒä¼šç®—å‡º [0, 5, 10, 15...] è¿™æ ·çš„ç´¢å¼•
        indices = np.linspace(0, total_candidates - 1, MAX_IMAGES, dtype=int)
        # set å»é‡ + sorted æ’åºï¼šé˜²æ­¢æç«¯æƒ…å†µä¸‹äº§ç”Ÿé‡å¤ç´¢å¼•
        indices = sorted(list(set(indices)))
        
        # æ ¹æ®è®¡ç®—å‡ºçš„ç´¢å¼•ï¼Œä»å€™é€‰åˆ—è¡¨ä¸­æå–å›¾ç‰‡
        for idx in indices:
            final_images_list.append(all_candidates[idx])
    else:
        # å¦‚æœæ•°é‡æœªè¶…æ ‡ï¼Œåˆ™ç›´æ¥ä¿ç•™æ‰€æœ‰å›¾ç‰‡
        print(f"    âœ… å›¾ç‰‡æ•°é‡ ({total_candidates}) æœªè¶…æ ‡ï¼Œå…¨éƒ¨ä¿ç•™ã€‚")
        final_images_list = all_candidates

    # æ‰§è¡Œæ–‡ä»¶å¤åˆ¶æ“ä½œï¼šåªæŠŠæœ€ç»ˆé€‰ä¸­çš„ "ç²¾è‹±å›¾ç‰‡" æ”¾å…¥ extracted_images_dir (å³ raw_images)
    # è¿™æ ·åšæ˜¯ä¸ºäº†éš”ç¦»è„æ•°æ®ï¼Œç¡®ä¿ COLMAP åªå¤„ç†æœ€å¥½çš„å›¾ç‰‡
    for img_path in final_images_list:
        shutil.copy2(str(img_path), str(extracted_images_dir / img_path.name))
        
    print(f"    âœ… å·²å°† {len(final_images_list)} å¼ å¹²å‡€å›¾ç‰‡ç§»å…¥ COLMAP ä¸“ç”¨ç›®å½•ã€‚")
    print(f"    ğŸ§¹ æ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
    # åˆ é™¤ä¸´æ—¶ç›®å½• temp_dirï¼ŒèŠ‚çœç£ç›˜ç©ºé—´å¹¶ä¿æŒå·¥ä½œåŒºæ•´æ´
    shutil.rmtree(temp_dir) # åˆ æ‰è„åŒºï¼Œé˜²æ­¢æ··æ·†

    # =========================================================
    # ğŸš€ COLMAP å¯åŠ¨
    # =========================================================
    
    print(f"    âœ… å‡†å¤‡å¯åŠ¨ COLMAP (Linux GPU æ¨¡å¼)...")
    
    # å®šä¹‰ COLMAP è¾“å‡ºçš„æ•°æ®åº“è·¯å¾„ (database.db æ˜¯ COLMAP å­˜å‚¨ç‰¹å¾ç‚¹å’ŒåŒ¹é…å…³ç³»çš„æ ¸å¿ƒæ–‡ä»¶)
    colmap_output_dir = data_dir / "colmap"
    colmap_output_dir.mkdir(parents=True, exist_ok=True)
    database_path = colmap_output_dir / "database.db"
    
    # å°è¯•ä½¿ç”¨ç»å¯¹è·¯å¾„è°ƒç”¨ç³»ç»Ÿå®‰è£…çš„ COLMAP
    system_colmap_exe = "/usr/local/bin/colmap" 
    
    # åŒé‡ä¿é™©æœºåˆ¶ï¼šæ£€æŸ¥è¯¥è·¯å¾„ä¸‹çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(system_colmap_exe):
        # å¦‚æœæŒ‡å®šè·¯å¾„ä¸å­˜åœ¨ï¼Œä½¿ç”¨ shutil.which åœ¨ç³»ç»Ÿ PATH ä¸­è‡ªåŠ¨æŸ¥æ‰¾ "colmap" å‘½ä»¤
        found_path = shutil.which("colmap")
        # æ’é™¤æ‰ conda ç¯å¢ƒè‡ªå¸¦çš„é˜‰å‰²ç‰ˆ colmap (é€šå¸¸ conda çš„ colmap æ²¡æœ‰ CUDA æ”¯æŒ)
        if found_path and "conda" not in found_path:
            system_colmap_exe = found_path
            print(f"    âš ï¸ è­¦å‘Š: /usr/local/bin/colmap ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨: {system_colmap_exe}")
        else:
            # å¦‚æœä¹Ÿæ²¡æ‰¾åˆ°ï¼Œåç»­æ‰§è¡Œå¯èƒ½ä¼šæŠ¥é”™ï¼Œä½†è¿™é‡Œä¸åšå¤„ç†ï¼Œä¾èµ–ç³»ç»ŸæŠ›å‡ºå¼‚å¸¸
            pass

    full_log_content = [] # ç”¨äºå­˜å‚¨ COLMAP çš„æ‰€æœ‰æ—¥å¿—è¾“å‡ºï¼Œä»¥ä¾¿åç»­è¿›è¡Œæ­£åˆ™åˆ†æ

    # å®šä¹‰ä¸€ä¸ªå†…éƒ¨å‡½æ•°ï¼Œç”¨äºæ‰§è¡Œ COLMAP çš„å„ä¸ªå­å‘½ä»¤
    def run_colmap_step(cmd, step_desc):
        """
        å‚æ•°:
            cmd: å‘½ä»¤è¡Œå‚æ•°åˆ—è¡¨ (list)
            step_desc: æ­¥éª¤æè¿°å­—ç¬¦ä¸² (ç”¨äºæ‰“å°æ—¥å¿—)
        """
        print(f"\nâš¡ {step_desc}...")
        try:
            # subprocess.Popen: å¯åŠ¨å­è¿›ç¨‹
            # stdout=subprocess.PIPE, stderr=subprocess.STDOUT: å°†æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯è¾“å‡ºåˆå¹¶æ•è·
            # text=True: ä»¥æ–‡æœ¬å½¢å¼è¯»å–è¾“å‡º
            # bufsize=1: è¡Œç¼“å†²ï¼Œå®æ—¶è¾“å‡º
            with subprocess.Popen(
                cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.STDOUT,
                text=True, 
                env=env, # ä¼ å…¥ç¯å¢ƒå˜é‡ (åŒ…å« QT_QPA_PLATFORM="offscreen" é˜²æ­¢å¼¹çª—)
                bufsize=1 
            ) as process:
                # å®æ—¶é€è¡Œè¯»å–æ—¥å¿—å¹¶æ‰“å°ï¼Œè®©ç”¨æˆ·çœ‹åˆ°è¿›åº¦
                for line in process.stdout:
                    print(line, end='') 
                    full_log_content.append(line) # åŒæ—¶ä¿å­˜åˆ°åˆ—è¡¨ä¸­
                
                process.wait() # ç­‰å¾…å­è¿›ç¨‹ç»“æŸ
                if process.returncode != 0: # å¦‚æœè¿”å›å€¼ä¸ä¸º0ï¼Œè¯´æ˜æ‰§è¡Œå‡ºé”™
                    raise subprocess.CalledProcessError(process.returncode, cmd)
        except Exception as e:
            print(f"\nâŒ {step_desc} æ‰§è¡Œå¼‚å¸¸: {e}")
            raise e # å‘ä¸ŠæŠ›å‡ºå¼‚å¸¸ï¼Œä¸­æ–­æµç¨‹

    # 3. æ‰‹åŠ¨è¿è¡Œ Feature Extractor (ç‰¹å¾æå–)
    # COLMAP ç¬¬ä¸€æ­¥ï¼šåˆ†ææ¯å¼ å›¾ç‰‡ï¼Œæå– SIFT ç‰¹å¾ç‚¹
    # æ³¨æ„ï¼šè¿™é‡Œç§»é™¤äº† --SiftExtraction.use_gpu å‚æ•°ï¼Œå› ä¸ºæ–°ç‰ˆ COLMAP å¦‚æœæ£€æµ‹åˆ° CUDA ä¼šè‡ªåŠ¨å¼€å¯ï¼Œ
    # æ˜¾å¼æŒ‡å®šåœ¨æŸäº› CPU æœºå™¨ä¸Šåè€Œä¼šæŠ¥é”™ã€‚
    run_colmap_step([
        system_colmap_exe, "feature_extractor",
        "--database_path", str(database_path), # æ•°æ®åº“æ–‡ä»¶
        "--image_path", str(extracted_images_dir), # å›¾ç‰‡ç›®å½•
        "--ImageReader.camera_model", "OPENCV", # æŒ‡å®šç›¸æœºæ¨¡å‹ä¸º OpenCV (å¸¸ç”¨ä¸”å…¼å®¹æ€§å¥½)
        "--ImageReader.single_camera", "1" # å‡è®¾æ‰€æœ‰å›¾ç‰‡æ¥è‡ªåŒä¸€ä¸ªç›¸æœº (å…±ç”¨å†…å‚)ï¼Œæœ‰åŠ©äºæé«˜é‡å»ºç¨³å®šæ€§
    ], "[1/4] GPU ç‰¹å¾æå–")

    # 4. æ‰‹åŠ¨è¿è¡Œ Sequential Matcher (é¡ºåºåŒ¹é…)
    # COLMAP ç¬¬äºŒæ­¥ï¼šåŒ¹é…ç‰¹å¾ç‚¹ã€‚å› ä¸ºæ˜¯è§†é¢‘æŠ½å¸§ï¼Œå›¾ç‰‡ä¹‹é—´æœ‰æ—¶é—´è¿ç»­æ€§ï¼Œ
    # æ‰€ä»¥ä½¿ç”¨ sequential_matcher æ¯” exhaustive_matcher (ç©·ä¸¾) å¿«å¾—å¤šä¸”æ•ˆæœæ›´å¥½ã€‚
    run_colmap_step([
        system_colmap_exe, "sequential_matcher",
        "--database_path", str(database_path),
        "--SequentialMatching.overlap", "25" # å‡è®¾ç›¸é‚»çš„ 25 å¼ å›¾ç‰‡å¯èƒ½æœ‰é‡å ï¼Œåªåœ¨è¿™äº›èŒƒå›´å†…è¿›è¡ŒåŒ¹é…
    ], "[2/4] GPU é¡ºåºåŒ¹é…")

    # 4.5 æ‰‹åŠ¨è¿è¡Œ Mapper (ç¨€ç–é‡å»º) 
    # COLMAP ç¬¬ä¸‰æ­¥ï¼šåˆ©ç”¨åŒ¹é…å…³ç³»è®¡ç®—ç›¸æœºä½å§¿å’Œç¨€ç–ç‚¹äº‘
    # æˆ‘ä»¬éœ€è¦åˆ›å»º sparse/0 ç›®å½•ï¼Œè¿™æ˜¯ Nerfstudio é»˜è®¤è¯»å– COLMAP æ•°æ®çš„æ ‡å‡†ç»“æ„
    sparse_output_dir = colmap_output_dir / "sparse" / "0"
    sparse_output_dir.mkdir(parents=True, exist_ok=True)
    
    run_colmap_step([
        system_colmap_exe, "mapper",
        "--database_path", str(database_path),
        "--image_path", str(extracted_images_dir),
        "--output_path", str(sparse_output_dir) # å¼ºåˆ¶è¾“å‡ºåˆ° sparse/0
    ], "[3/4] ç¨€ç–é‡å»º (Mapper)")

    print(f"âœ… COLMAP è®¡ç®—å®Œæˆï¼æ­£åœ¨æ£€æŸ¥å¹¶ä¿®æ­£ç›®å½•ç»“æ„...")

    # =========================================================
    # ğŸ”§ [3.5] ç›®å½•ç»“æ„å¼ºåŠ›ä¿®æ­£ (Auto-Fixer)
    # èƒŒæ™¯ï¼šCOLMAP çš„ mapper å‘½ä»¤åœ¨ä¸åŒç‰ˆæœ¬è¡Œä¸ºä¸ä¸€è‡´ï¼Œæœ‰æ—¶å®ƒä¼šåœ¨ output_path ä¸‹å†å»ºä¸€å±‚ '0'ï¼Œ
    # æœ‰æ—¶åˆ™ç›´æ¥è¾“å‡ºã€‚ä¸ºäº†ä¿è¯åç»­æ­¥éª¤ä¸å‡ºé”™ï¼Œè¿™é‡Œå†™äº†ä¸€æ®µé€»è¾‘æ¥â€œçº æ­£â€æ–‡ä»¶ä½ç½®ã€‚
    # =========================================================
    
    colmap_root = colmap_output_dir  # .../data/colmap
    sparse_root = colmap_root / "sparse"
    target_dir_0 = sparse_root / "0"
    target_dir_0.mkdir(parents=True, exist_ok=True) # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨

    # å®šä¹‰ COLMAP æ¨¡å‹çš„ä¸¤å¥—æ ‡å‡†æ–‡ä»¶å (äºŒè¿›åˆ¶ bin æˆ– æ–‡æœ¬ txt)
    required_files_bin = ["cameras.bin", "images.bin", "points3D.bin"]
    required_files_txt = ["cameras.txt", "images.txt", "points3D.txt"]
    
    model_found = False # æ ‡è®°æ˜¯å¦æ‰¾åˆ°äº†å®Œæ•´çš„æ¨¡å‹æ–‡ä»¶

    # 1. æ£€æŸ¥æ˜¯ä¸æ˜¯å·²ç»åœ¨ sparse/0 (å®Œç¾æƒ…å†µï¼Œä¸éœ€è¦åŠ¨)
    if all((target_dir_0 / f).exists() for f in required_files_bin):
        print("    âœ… æ¨¡å‹æ–‡ä»¶ (BIN) ä½ç½®æ­£ç¡®ã€‚")
        model_found = True
    elif all((target_dir_0 / f).exists() for f in required_files_txt):
        print("    âœ… æ¨¡å‹æ–‡ä»¶ (TXT) ä½ç½®æ­£ç¡®ã€‚")
        model_found = True
        
    # 2. æ£€æŸ¥æ˜¯ä¸æ˜¯åœ¨ sparse æ ¹ç›®å½• (å¸¸è§é”™è¯¯æƒ…å†µ) -> éœ€è¦æ¬è¿åˆ° sparse/0
    if not model_found:
        if all((sparse_root / f).exists() for f in required_files_bin):
            print("    ğŸ”§ æ£€æµ‹åˆ° BIN æ¨¡å‹åœ¨ sparse æ ¹ç›®å½•ï¼Œæ­£åœ¨å½’ä½...")
            for f in required_files_bin:
                shutil.move(str(sparse_root / f), str(target_dir_0 / f)) # ç§»åŠ¨æ–‡ä»¶
            model_found = True
        elif all((sparse_root / f).exists() for f in required_files_txt):
            print("    ğŸ”§ æ£€æµ‹åˆ° TXT æ¨¡å‹åœ¨ sparse æ ¹ç›®å½•ï¼Œæ­£åœ¨å½’ä½...")
            for f in required_files_txt:
                shutil.move(str(sparse_root / f), str(target_dir_0 / f))
            model_found = True

    # 3. é€’å½’æœç´¢ï¼šå¦‚æœä¸Šé¢éƒ½æ²¡æ‰¾åˆ°ï¼Œå¯èƒ½åœ¨æ›´æ·±çš„å­ç›®å½• (å¦‚ sparse/1 æˆ– sparse/0/0)
    if not model_found:
        # os.walk éå†æ‰€æœ‰å­ç›®å½•
        for root, dirs, files in os.walk(sparse_root):
            # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦æœ‰ bin æ¨¡å‹
            if all(f in files for f in required_files_bin):
                src_path = Path(root)
                if src_path == target_dir_0: continue # è·³è¿‡ç›®æ ‡ç›®å½•è‡ªå·±
                print(f"    ğŸ”§ åœ¨å­ç›®å½• {src_path} æ‰¾åˆ° BIN æ¨¡å‹ï¼Œæ­£åœ¨å½’ä½...")
                for f in required_files_bin:
                    shutil.move(str(src_path / f), str(target_dir_0 / f))
                model_found = True
                break
            # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦æœ‰ txt æ¨¡å‹
            if all(f in files for f in required_files_txt):
                src_path = Path(root)
                if src_path == target_dir_0: continue
                print(f"    ğŸ”§ åœ¨å­ç›®å½• {src_path} æ‰¾åˆ° TXT æ¨¡å‹ï¼Œæ­£åœ¨å½’ä½...")
                for f in required_files_txt:
                    shutil.move(str(src_path / f), str(target_dir_0 / f))
                model_found = True
                break

    # å¦‚æœæ‰¾äº†ä¸€åœˆè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œè¯´æ˜ COLMAP å½»åº•å¤±è´¥äº†
    if not model_found:
        print("âŒ [ä¸¥é‡é”™è¯¯] åœ¨ sparse ç›®å½•ä¸‹æ‰¾ä¸åˆ°å®Œæ•´çš„ COLMAP æ¨¡å‹æ–‡ä»¶ï¼")
        print("    -> å¯èƒ½åŸå› ï¼šMapper å¤±è´¥ï¼Œæœªèƒ½é‡å»ºå‡ºåœºæ™¯ã€‚")
        # æŠ›å‡ºæ–‡ä»¶æœªæ‰¾åˆ°å¼‚å¸¸ï¼Œç»ˆæ­¢ç¨‹åº
        raise FileNotFoundError("COLMAP Mapper failed to generate valid model files.")

    # [3.6] æå‰åŒæ­¥å›¾ç‰‡ (ä¸ºäº†è®© ns-process-data èƒ½æ‰¾åˆ°)
    # Nerfstudio è¦æ±‚å›¾ç‰‡å¿…é¡»åœ¨ data/images ç›®å½•ä¸‹ï¼Œè€Œæˆ‘ä»¬ä¹‹å‰æ˜¯åœ¨ raw_images
    print(f"    -> æ­£åœ¨åŒæ­¥å›¾ç‰‡: raw_images -> data/images ...")
    dest_images_dir = data_dir / "images"
    dest_images_dir.mkdir(parents=True, exist_ok=True)
    
    valid_images = []
    # å†æ¬¡æœç´¢æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    for ext in ["*.jpg", "*.jpeg", "*.png", "*.JPG", "*.PNG"]:
        valid_images.extend(list(extracted_images_dir.glob(ext)))
        
    for img_path in valid_images:
        shutil.copy2(str(img_path), str(dest_images_dir / img_path.name))
    print(f"    âœ… å·²åŒæ­¥ {len(valid_images)} å¼ å›¾ç‰‡ã€‚")

    print(f"âœ… æ•°æ®å‡†å¤‡å°±ç»ªï¼æ­£åœ¨ç”Ÿæˆ transforms.json (ç”¨äºåç»­åˆ‡å‰²)...")

    # 5. è¿è¡Œ ns-process-data (ç”Ÿæˆ transforms.json)
    # åŠŸèƒ½ï¼šå°† COLMAP çš„äºŒè¿›åˆ¶æ•°æ®è½¬æ¢ä¸º Nerfstudio æ‰€éœ€çš„ JSON æ ¼å¼
    # å…³é”®å‚æ•°ï¼š
    # --skip-colmap: æˆ‘ä»¬ä¹‹å‰æ‰‹åŠ¨è·‘è¿‡ COLMAP äº†ï¼Œè¿™é‡Œè·³è¿‡
    # --skip-image-processing: å›¾ç‰‡ä¹Ÿå¤„ç†è¿‡äº†ï¼Œè·³è¿‡
    # --num-downscales 0: ä¸ç”Ÿæˆç¼©ç•¥å›¾ï¼ŒèŠ‚çœæ—¶é—´
    run_colmap_step([
        "ns-process-data", "images", 
            "--data", str(dest_images_dir), 
            "--output-dir", str(data_dir), 
            "--verbose", 
            "--skip-colmap", 
            "--skip-image-processing", 
            "--num-downscales", "0"
    ], "[4/4] ç”Ÿæˆ transforms.json")

    # --- è´¨é‡æ£€æµ‹é€»è¾‘ ---
    # å°†ä¹‹å‰çš„æ—¥å¿—åˆ—è¡¨åˆå¹¶æˆä¸€ä¸ªé•¿å­—ç¬¦ä¸²
    full_log = "".join(full_log_content)
    
    # 1. æ£€æµ‹ "No convergence" (ä¸æ”¶æ•›)
    # è¿™æ˜¯ COLMAP å¸¸è§çš„å¤±è´¥æŠ¥é”™ï¼Œè¡¨ç¤ºæ— æ³•ä»å›¾ç‰‡ä¸­è§£ç®—å‡º 3D ç»“æ„
    if "Termination : No convergence" in full_log:
        print("\nâŒ [ä¸¥é‡é”™è¯¯] COLMAP æ— æ³•æ”¶æ•› (No convergence)ï¼")
        
        # å°è¯•æå–åŒ¹é…ç‡ï¼Œå‘ŠçŸ¥ç”¨æˆ·æœ‰å¤šç³Ÿç³•
        match_pct = re.search(r"COLMAP only found poses for (\d+\.?\d*)% of the images", full_log)
        if match_pct:
            print(f"    -> æˆåŠŸæ³¨å†Œå›¾ç‰‡æ¯”ä¾‹: {match_pct.group(1)}% (è´¨é‡è¿‡ä½)")
        else:
            # å¤‡é€‰æ–¹æ¡ˆï¼šé€šè¿‡æ­£åˆ™æŸ¥æ‰¾ "Registered images" å…³é”®è¯æ¥è®¡ç®—æ¯”ä¾‹
            reg_match = re.findall(r"Registered images.*?(\d+)", full_log)
            if reg_match:
                registered_count = int(reg_match[-1])
                # æ³¨æ„ï¼šè¿™é‡Œ num_images å˜é‡å¯èƒ½æ˜¯å¼•ç”¨ä¹‹å‰çš„ total_candidatesï¼Œä»£ç æ­¤å¤„å¯èƒ½æœ‰ä¸Šä¸‹æ–‡ä¾èµ–
                ratio = (registered_count / total_candidates) * 100 if total_candidates > 0 else 0
                print(f"    -> æˆåŠŸæ³¨å†Œå›¾ç‰‡: {registered_count}/{total_candidates} ({ratio:.2f}%)")
            
        print("ğŸ›‘ ä»»åŠ¡å·²ç»ˆæ­¢ï¼Œå› ä¸ºç”Ÿæˆçš„ç¨€ç–ç‚¹äº‘è´¨é‡æ— æ³•æ»¡è¶³è®­ç»ƒè¦æ±‚ã€‚")
        
        # å¤±è´¥åæ¸…ç†å·¥ä½œç›®å½•
        if work_dir.exists():
            shutil.rmtree(work_dir)
            print(f"ğŸ§¹ æ¸…ç†å®Œæˆ: å·²åˆ é™¤å·¥ä½œåŒº {work_dir}")
        return None

    # 2. æ£€æµ‹åŒ¹é…ç‡è¿‡ä½
    # å³ä½¿æ”¶æ•›äº†ï¼Œå¦‚æœåªæœ‰ 10% çš„å›¾ç‰‡è¢«åŒ¹é…ä¸Šï¼Œè®­ç»ƒå‡ºæ¥çš„ç»“æœä¹Ÿä¼šå¾ˆå·®
    match = re.search(r"COLMAP only found poses for (\d+\.?\d*)% of the images", full_log)
    if match:
        matched_percentage = float(match.group(1))
        print(f"\nğŸ“Š COLMAP åŒ¹é…ç‡æ£€æµ‹: {matched_percentage:.2f}%")
        
        if matched_percentage < 35.0: # é˜ˆå€¼ï¼š35%
            print(f"âŒ [è´¨é‡è­¦å‘Š] åŒ¹é…ç‡è¿‡ä½ (< 35%)ï¼")
            print("    -> è¿™æ„å‘³ç€å¤§éƒ¨åˆ†å›¾ç‰‡æ— æ³•è¢«å®šä½ï¼Œç”Ÿæˆçš„ 3D åœºæ™¯å°†ä¸¥é‡æ®‹ç¼ºã€‚")
            print("ğŸ›‘ ä»»åŠ¡å·²ç»ˆæ­¢ã€‚å»ºè®®ï¼šå¢åŠ å›¾ç‰‡æ•°é‡ã€ä¿è¯å›¾ç‰‡æ¸…æ™°åº¦æˆ–å¢åŠ é‡å ç‡ã€‚")
            
            if work_dir.exists():
                shutil.rmtree(work_dir)
                print(f"ğŸ§¹ æ¸…ç†å®Œæˆ: å·²åˆ é™¤å·¥ä½œåŒº {work_dir}")
            return None

    step1_duration = time.time() - step1_start
    print(f"â±ï¸ [Step 1 å®Œæˆ] è€—æ—¶: {format_duration(step1_duration)}")

    # [Step 2] è®­ç»ƒ
    step2_start = time.time()
    # å®šä¹‰è®­ç»ƒè¾“å‡ºè·¯å¾„
    search_path = output_dir / project_name / "splatfacto"
    # æ£€æŸ¥æ˜¯å¦å·²ç»è®­ç»ƒè¿‡ (å¦‚æœæœ‰æ–­ç‚¹ç»­ä¼ çš„éœ€æ±‚)
    run_dirs = sorted(list(search_path.glob("*"))) if search_path.exists() else []
    
    scene_type_detected = "unknown"

    if run_dirs:
        # å¦‚æœæ‰¾åˆ°æ—§çš„è®­ç»ƒç›®å½•ï¼Œè·³è¿‡è®­ç»ƒ (æ­¤å¤„é€»è¾‘æ˜¯ä¸ºäº†é˜²é‡å¤ï¼Œæˆ–è€…è°ƒè¯•ç”¨)
        print(f"\nâ© [è®­ç»ƒè·³è¿‡] å·²å®Œæˆ")
        _, scene_type_detected = analyze_and_calculate_adaptive_collider(transforms_file)
    else:
        # è°ƒç”¨ä¹‹å‰å®šä¹‰çš„ AI åˆ†æå‡½æ•°ï¼Œè®¡ç®—åœºæ™¯å‚æ•° (collider args)
        collider_args, scene_type_detected = analyze_and_calculate_adaptive_collider(transforms_file)
        print(f"\nğŸ§  [2/3] å¼€å§‹è®­ç»ƒ...")
        
        # å¯åŠ¨ ns-train (Nerfstudio è®­ç»ƒä¸»ç¨‹åº)
        subprocess.run([
            "ns-train", "splatfacto", # æŒ‡å®šæ¨¡å‹ä¸º splatfacto (Nerfstudio çš„ 3DGS å®ç°)
            "--data", str(data_dir), # æ•°æ®è·¯å¾„
            "--output-dir", str(output_dir), # è¾“å‡ºè·¯å¾„
            "--experiment-name", project_name, # å®éªŒåç§°
            "--pipeline.model.random-init", "False", # å…³é—­éšæœºåˆå§‹åŒ–ï¼Œåˆ©ç”¨ç¨€ç–ç‚¹äº‘åˆå§‹åŒ–
            "--pipeline.model.cull-alpha-thresh", "0.005", # é€æ˜åº¦å‰”é™¤é˜ˆå€¼
            *collider_args, # è§£åŒ…ä¼ å…¥åŠ¨æ€è®¡ç®—çš„ collider å‚æ•° (near/far planes)
            "--max-num-iterations", "15000", # æœ€å¤§è¿­ä»£æ¬¡æ•° 15000 æ­¥
            "--vis", "viewer+tensorboard", # å¼€å¯å¯è§†åŒ–æ”¯æŒ
            "--viewer.quit-on-train-completion", "True", # è®­ç»ƒå®Œè‡ªåŠ¨å…³é—­ Viewer åå°
            
            # ğŸ‘‡ å­å‘½ä»¤ï¼šæŒ‡å®šä½¿ç”¨ colmap æ•°æ®è§£æå™¨
            "colmap", 
            
            # ğŸ‘‡ å‚æ•°ä¿®æ­£ï¼šåªéœ€å†™çŸ­åï¼Œå¹¶ä¸”å¿…é¡»æ”¾åœ¨ "colmap" åé¢
            "--downscale-factor", "1" # ä¸å¯¹å›¾ç‰‡è¿›è¡Œç¼©æ”¾ï¼Œä½¿ç”¨åŸå›¾åˆ†è¾¨ç‡è®­ç»ƒ
        ], check=True, env=env)

    step2_duration = time.time() - step2_start
    print(f"â±ï¸ [Step 2 å®Œæˆ] è€—æ—¶: {format_duration(step2_duration)}")

    # [Step 3] å¯¼å‡º
    step3_start = time.time()
    print(f"\nğŸ’¾ [3/3] å¯¼å‡ºç»“æœ")
    # é‡æ–°æŸ¥æ‰¾è®­ç»ƒç»“æœç›®å½• (ç¡®ä¿æ‹¿åˆ°æœ€æ–°ä¸€æ¬¡è®­ç»ƒçš„æ–‡ä»¶å¤¹)
    if not run_dirs: run_dirs = sorted(list(search_path.glob("*")))
    if not run_dirs: return None # å¦‚æœè¿˜æ˜¯ç©ºçš„ï¼Œè¯´æ˜è®­ç»ƒå¤±è´¥
    latest_run = run_dirs[-1] # å–æœ€æ–°çš„é‚£ä¸ª
    
    # è¿è¡Œ ns-exportï¼šå°†è®­ç»ƒå¥½çš„ checkpoint è½¬æ¢ä¸ºé€šç”¨çš„ .ply æˆ– .splat æ–‡ä»¶
    subprocess.run([
        "ns-export", "gaussian-splat", # å¯¼å‡ºæ¨¡å¼
        "--load-config", str(latest_run/"config.yml"), # åŠ è½½å¯¹åº”çš„é…ç½®æ–‡ä»¶
        "--output-dir", str(work_dir) # å¯¼å‡ºåˆ°å·¥ä½œæ ¹ç›®å½•
    ], check=True, env=env)
    time.sleep(5) # ç­‰å¾…æ–‡ä»¶ç³»ç»ŸåŒæ­¥

    # [Step 3.5] åˆ†ä½æ•°æš´åŠ›åˆ‡å‰² (æ ¸å¿ƒåå¤„ç†)
    # æ£€æŸ¥å¯¼å‡ºçš„æ–‡ä»¶å¯èƒ½æ˜¯ point_cloud.ply æˆ– splat.ply
    raw_ply = work_dir / "point_cloud.ply"
    if not raw_ply.exists(): raw_ply = work_dir / "splat.ply"

    cleaned_ply = work_dir / "point_cloud_cleaned.ply" # åˆ‡å‰²åçš„æ–‡ä»¶å
    final_ply_to_use = raw_ply # é»˜è®¤ä½¿ç”¨åŸå§‹æ–‡ä»¶

    # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ‡å‰²ï¼šå¦‚æœæ˜¯ç‰©ä½“æ¨¡å¼ï¼Œæˆ–è€…å¼ºåˆ¶å¼€å¯äº†åˆ‡å‰²
    should_clean = (scene_type_detected == "object") or FORCE_SPHERICAL_CULLING
    
    if should_clean:
        if raw_ply.exists():
            # è°ƒç”¨ä¹‹å‰çš„ perform_percentile_culling å‡½æ•°
            if perform_percentile_culling(raw_ply, transforms_file, cleaned_ply):
                print("âœ¨ æš´åŠ›åˆ‡å‰²æˆåŠŸï¼")
                final_ply_to_use = cleaned_ply # æŒ‡å‘åˆ‡å‰²åçš„æ–‡ä»¶
        else:
            print(f"âŒ è­¦å‘Šï¼šæœªæ‰¾åˆ° PLY æ–‡ä»¶")
    else:
        print(f"â„¹ï¸ è·³è¿‡åˆ‡å‰²")

    step3_duration = time.time() - step3_start
    print(f"â±ï¸ [Step 3 å®Œæˆ] è€—æ—¶: {format_duration(step3_duration)}")
# ... æ¥ä¸Šæ–‡ Run Pipeline å‡½æ•°çš„æœ«å°¾éƒ¨åˆ† ...

    # =========================================================
    # ğŸ“¦ [Step 4] ç»“æœå›ä¼ ä¸ç¯å¢ƒæ¸…ç†
    # è¿™ä¸€æ­¥éå¸¸å…³é”®ï¼Œå®ƒè´Ÿè´£å°† Linux (WSL/Server) ç®—å¥½çš„ç»“æœ
    # æ¬è¿å› Windows æˆ–ç»“æœç›®å½•ï¼Œå¹¶æ¸…ç†åºå¤§çš„ä¸´æ—¶æ–‡ä»¶ã€‚
    # =========================================================
    
    print(f"\nğŸ“¦ [IO åŒæ­¥] å›ä¼ è‡³ Windows...")
    
    # 1. å®šä¹‰ç»“æœå­˜æ”¾çš„ç›®æ ‡ç›®å½•
    # Path(__file__).parent è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„æ–‡ä»¶å¤¹
    # / "results" åœ¨è„šæœ¬åŒçº§ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª results æ–‡ä»¶å¤¹
    target_dir = Path(__file__).parent / "results"
    target_dir.mkdir(exist_ok=True, parents=True) # ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
    
    # 2. å®šä¹‰æºæ–‡ä»¶è·¯å¾„ (åœ¨å·¥ä½œåŒºä¸­) å’Œ ç›®æ ‡æ–‡ä»¶è·¯å¾„ (åœ¨ç»“æœç›®å½•ä¸­)
    transforms_src = data_dir / "transforms.json" # æºï¼šNerfstudio ç”Ÿæˆçš„ç›¸æœºå‚æ•°
    
    # ç›®æ ‡ï¼šWebGL å‰ç«¯ä¸“ç”¨çš„å§¿æ€æ–‡ä»¶ (ç®€åŒ–ç‰ˆ)
    final_webgl_poses = target_dir / "webgl_poses.json" 
    # ç›®æ ‡ï¼šæœ€ç»ˆçš„ç‚¹äº‘æ¨¡å‹æ–‡ä»¶
    final_ply_dst = target_dir / f"{project_name}.ply"
    # ç›®æ ‡ï¼šæ ‡å‡†çš„ç›¸æœºå‚æ•°æ–‡ä»¶å¤‡ä»½
    final_transforms = target_dir / "transforms.json"
    
    # --- æ ¸å¿ƒé€»è¾‘ï¼šç”Ÿæˆ WebGL å‹å¥½å§¿æ€æ–‡ä»¶ ---
    # Nerfstudio çš„ transforms.json åŒ…å«å¾ˆå¤šè®­ç»ƒå‚æ•°ï¼Œå‰ç«¯ WebGL å±•ç¤ºæ—¶ä¸éœ€è¦é‚£ä¹ˆå¤š
    # è¿™é‡Œæˆ‘ä»¬ç”Ÿæˆä¸€ä¸ªè½»é‡çº§çš„ jsonï¼ŒåªåŒ…å«ç›¸æœºä½å§¿çŸ©é˜µã€‚
    if transforms_src.exists():
        print("ğŸ”„ æ­£åœ¨ç”Ÿæˆ WebGL å‹å¥½å§¿æ€æ–‡ä»¶ (webgl_poses.json)...")
        try:
            with open(transforms_src, 'r') as f:
                data = json.load(f) # è¯»å–åŸå§‹ JSON
            
            webgl_frames = []
            # éå†æ¯ä¸€å¸§ (æ¯ä¸€å¼ ç…§ç‰‡)
            for frame in data["frames"]:
                # æå– 4x4 å˜æ¢çŸ©é˜µ (Camera to World)
                c2w_matrix = np.array(frame["transform_matrix"], dtype=np.float32)
                
                # å°†çŸ©é˜µè½¬ä¸º list å¹¶å­˜å…¥æ–°ç»“æ„
                webgl_frames.append({
                    "file_path": frame["file_path"], # å›¾ç‰‡è·¯å¾„
                    "pose_matrix_c2w": c2w_matrix.tolist() # çŸ©é˜µæ•°æ®
                })
                
            # æ„é€ ç²¾ç®€ç‰ˆçš„æ•°æ®å­—å…¸
            webgl_data = {
                "camera_model": data.get("camera_model", "OPENCV"), # ç›¸æœºæ¨¡å‹
                "w": data.get("w", 0), # å®½
                "h": data.get("h", 0), # é«˜
                "fl_x": data.get("fl_x", 0), # ç„¦è· X
                "fl_y": data.get("fl_y", 0), # ç„¦è· Y
                "frames": webgl_frames # å¸§æ•°æ®
            }
            
            # å†™å…¥ webgl_poses.json
            with open(final_webgl_poses, 'w') as f:
                json.dump(webgl_data, f, indent=4)
            print(f"âœ… WebGL å§¿æ€æ–‡ä»¶å·²ä¿å­˜è‡³: {final_webgl_poses.resolve()}")
        except Exception as e:
            print(f"âŒ å§¿æ€é¢„å¤„ç†å¤±è´¥: {e}")

    # --- æ–‡ä»¶å¤åˆ¶ä¸å·¥ä½œåŒºæ¸…ç† ---
    # final_ply_to_use æ˜¯åœ¨ä¸Šä¸€æ­¥ (Step 3) ä¸­ç¡®å®šçš„æœ€ç»ˆ PLY è·¯å¾„ (å¯èƒ½æ˜¯åŸç‰ˆï¼Œä¹Ÿå¯èƒ½æ˜¯åˆ‡å‰²ç‰ˆ)
    if final_ply_to_use and final_ply_to_use.exists():
        try:
            # 1. å¤åˆ¶æœ€ç»ˆ PLY æ¨¡å‹åˆ°ç»“æœç›®å½•
            # shutil.copy2 ä¼šä¿ç•™æ–‡ä»¶çš„å…ƒæ•°æ® (åˆ›å»ºæ—¶é—´ç­‰)
            shutil.copy2(str(final_ply_to_use), str(final_ply_dst))
            
            # 2. é¢å¤–å¤‡ä»½åŸå§‹æ¨¡å‹ (Raw Model)
            # å¦‚æœæˆ‘ä»¬è¿›è¡Œäº†åˆ‡å‰² (Culling)ï¼Œä¸ºäº†é˜²æ­¢åˆ‡åäº†æ²¡æ³•è¡¥æ•‘ï¼Œ
            # è¿™é‡ŒæŠŠæœªåˆ‡å‰²çš„åŸå§‹ point_cloud.ply ä¹Ÿå¤åˆ¶ä¸€ä»½ï¼Œå‘½åä¸º *_raw.ply
            final_raw_ply_dst = target_dir / f"{project_name}_raw.ply"
            if raw_ply.exists():
                shutil.copy2(str(raw_ply), str(final_raw_ply_dst))
                print(f"    -> åŸå§‹æ¨¡å‹å·²å¤‡ä»½: {final_raw_ply_dst.name}")
            
            # 3. å¤åˆ¶ transforms.json
            if transforms_src.exists():
                shutil.copy2(str(transforms_src), str(final_transforms))
            
            # 4. ğŸ”¥ã€é‡è¦ã€‘æ¸…ç† Linux å·¥ä½œåŒº
            # braindance_workspace ç›®å½•é€šå¸¸åŒ…å«æ•°åƒå¼ è§£å‹çš„å›¾ç‰‡å’Œå·¨å¤§çš„ checkpoint æ–‡ä»¶
            # ä»»åŠ¡å®Œæˆåå¿…é¡»åˆ é™¤ï¼Œå¦åˆ™ç¡¬ç›˜å¾ˆå¿«ä¼šæ»¡ã€‚
            shutil.rmtree(work_dir)
            print(f"ğŸ§¹ æ¸…ç†å®Œæˆ: å·²åˆ é™¤å·¥ä½œåŒº {work_dir}")
            
            # --- æœ€ç»ˆç»Ÿè®¡ ---
            total_time = time.time() - global_start_time # è®¡ç®—æ€»è€—æ—¶
            print(f"\nâœ… =============================================")
            print(f"ğŸ‰ ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼å®‰å¿ƒç¡è§‰å§ã€‚")
            print(f"ğŸ“‚ æœ€ç»ˆæ¨¡å‹: {final_ply_dst}")
            print(f"â±ï¸ æ€»å…±è€—æ—¶: {format_duration(total_time)}")
            print(f"âœ… =============================================")
            
            return str(final_ply_dst) # è¿”å›æœ€ç»ˆè·¯å¾„ï¼Œä¾›å¤–éƒ¨è°ƒç”¨è€…ä½¿ç”¨
        except Exception as e:
            print(f"âŒ å›ä¼ å¤±è´¥: {e}")
            return None
    else:
        # å¦‚æœæ‰¾ä¸åˆ° PLY æ–‡ä»¶ï¼Œè¯´æ˜ä¹‹å‰çš„æ­¥éª¤è‚¯å®šå‡ºé”™äº†
        print("âŒ å¯¼å‡ºå¤±è´¥ï¼Œæœªæ‰¾åˆ° PLY æ–‡ä»¶ (point_cloud.ply æˆ– splat.ply)ã€‚")
        return None

# =========================================================
# ğŸ¬ ç¨‹åºä¸»å…¥å£ (Main Entry)
# =========================================================
if __name__ == "__main__":
    # è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„
    script_dir = Path(__file__).resolve().parent
    
    # é»˜è®¤è§†é¢‘æ–‡ä»¶è·¯å¾„: å½“å‰ç›®å½•ä¸‹çš„ test.mp4
    video_file = script_dir / "test.mp4" 
    
    # å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ
    # å¦‚æœç”¨æˆ·è¿è¡Œ: python script.py my_video.mov
    # sys.argv[1] å°±ä¼šè·å–åˆ° "my_video.mov"ï¼Œè¦†ç›–é»˜è®¤å€¼
    if len(sys.argv) > 1: video_file = Path(sys.argv[1])

    # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
    if video_file.exists():
        # å¯åŠ¨ä¸»æµç¨‹ï¼
        # é¡¹ç›®åç§°å®šä¸º "scene_auto_sync"ï¼Œè¿™æ„å‘³ç€æ¯æ¬¡è¿è¡Œéƒ½ä¼šè¦†ç›–è¿™ä¸ªé¡¹ç›®åä¸‹çš„æ•°æ®
        # (å› ä¸ºå‰é¢çš„ä»£ç é‡Œæœ‰ shutil.rmtree(work_dir) çš„é‡ç½®é€»è¾‘)
        run_pipeline(video_file, "scene_auto_sync")
    else:
        print(f"âŒ æ‰¾ä¸åˆ°è§†é¢‘: {video_file}")