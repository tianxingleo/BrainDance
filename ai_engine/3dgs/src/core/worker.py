import time
import os
from pathlib import Path

# å¼•å…¥ Supabase å®¢æˆ·ç«¯åº“ï¼Œç”¨äºè¿æ¥äº‘æ•°æ®åº“å’Œå­˜å‚¨
from supabase import create_client, Client
# å¼•å…¥ python-dotenv åº“ï¼Œç”¨äºåŠ è½½æœ¬åœ° .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ï¼ˆä¿æŠ¤å¯†é’¥å®‰å…¨ï¼‰
from dotenv import load_dotenv

# å¼•å…¥é¡¹ç›®å†…éƒ¨é…ç½®ç±»å’Œæ ¸å¿ƒç®¡çº¿å‡½æ•°
from src.config import PipelineConfig
from src.core.pipeline import run_pipeline

# [åˆå§‹åŒ–] åŠ è½½å½“å‰ç›®å½•ä¸‹çš„ .env æ–‡ä»¶
# è¿™ä¸€æ­¥å¿…é¡»åœ¨æ‰€æœ‰ os.getenv è°ƒç”¨ä¹‹å‰æ‰§è¡Œï¼Œå¦åˆ™è¯»ä¸åˆ°å˜é‡
load_dotenv()

class CloudWorker:
    """
    â˜ï¸ CloudWorker (äº‘ç«¯å·¥äºº)
    
    èŒè´£ï¼š
    1. æŒç»­ç›‘å¬ Supabase æ•°æ®åº“ä¸­çš„ä»»åŠ¡è¡¨ã€‚
    2. æŠ¢å•ï¼šå‘ç°çŠ¶æ€ä¸º 'pending' çš„ä»»åŠ¡å¹¶é”å®šã€‚
    3. æ‰§è¡Œï¼šä¸‹è½½è§†é¢‘ -> è°ƒç”¨ 3DGS æ ¸å¿ƒå¼•æ“ -> ç”Ÿæˆæ¨¡å‹ã€‚
    4. æ±‡æŠ¥ï¼šå®æ—¶åŒæ­¥æ—¥å¿—åˆ°æ•°æ®åº“ï¼Œå¹¶å°†æœ€ç»ˆç»“æœä¸Šä¼ å›äº‘å­˜å‚¨ã€‚
    """

    def __init__(self):
        """
        åˆå§‹åŒ– Workerï¼šè¿æ¥ Supabaseï¼Œå‡†å¤‡æœ¬åœ°ç¼“å­˜ç›®å½•ã€‚
        """
        # --- 1. è¯»å–ç¯å¢ƒå˜é‡é…ç½® ---
        # ä½¿ç”¨ os.getenv è¯»å– .env æ–‡ä»¶ä¸­çš„é…ç½®ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯é»˜è®¤å€¼
        self.SUPABASE_URL = os.getenv("SUPABASE_URL")
        self.SUPABASE_KEY = os.getenv("SUPABASE_KEY")
        self.BUCKET_NAME = os.getenv("SUPABASE_BUCKET", "braindance-assets")  # å­˜å‚¨æ¡¶åç§°
        self.TABLE_NAME = os.getenv("SUPABASE_TABLE", "processing_tasks")    # ä»»åŠ¡è¡¨åç§°
        
        # --- 2. é˜²å¾¡æ€§æ£€æŸ¥ ---
        # å¦‚æœå…³é”®é…ç½®ç¼ºå¤±ï¼Œç›´æ¥æŠ¥é”™åœæ­¢ï¼Œé¿å…åç»­å‡ºç°è«åå…¶å¦™çš„è¿æ¥é”™è¯¯
        if not self.SUPABASE_URL or not self.SUPABASE_KEY:
            raise ValueError("âŒ åˆå§‹åŒ–å¤±è´¥ï¼šæœªæ‰¾åˆ° Supabase é…ç½®ï¼è¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¡«å†™æ­£ç¡®ã€‚")

        # --- 3. å»ºç«‹è¿æ¥ ---
        # åˆ›å»º Supabase å®¢æˆ·ç«¯å®ä¾‹ï¼Œåç»­æ‰€æœ‰æ•°æ®åº“/å­˜å‚¨æ“ä½œéƒ½é€šè¿‡å®ƒè¿›è¡Œ
        self.supabase: Client = create_client(self.SUPABASE_URL, self.SUPABASE_KEY)
        
        # --- 4. å‡†å¤‡æœ¬åœ°å·¥ä½œåŒº ---
        # ğŸŸ¢ [ä¿®æ”¹å] æ‰¾å›åŸæ¥çš„ "braindance_workspace"ï¼Œå®ç°è·¯å¾„å½’ä¸€åŒ–
        # è¿™æ ·æ‰€æœ‰çš„ä»»åŠ¡æ•°æ®å’Œæ¨¡å‹éƒ½ä¼šå­˜æ”¾åœ¨ /home/ltx/braindance_workspace
        self.CACHE_DIR = Path.home() / "braindance_workspace"
        self.CACHE_DIR.mkdir(parents=True, exist_ok=True)
        
        # ğŸŸ¢ [æ–°å¢] å®šä¹‰ä¸€ä¸ªå…¬å…±æ¨¡å‹ç›®å½•ï¼Œç”¨äºå­˜æ”¾ SAM æƒé‡ç­‰ï¼Œå®ç°å¤šä»»åŠ¡å…±äº«
        self.MODELS_DIR = self.CACHE_DIR / "models"
        self.MODELS_DIR.mkdir(exist_ok=True)
        
        # --- 5. åˆå§‹åŒ–æ—¥å¿—ç¼“å†²åŒº ---
        # [å…³é”®è®¾è®¡] ç”¨äºè§£å†³â€œè¯»å†™å†²çªâ€é—®é¢˜ã€‚
        # æˆ‘ä»¬ä¸å†æ¯æ¬¡ Select æ•°æ®åº“ï¼Œè€Œæ˜¯å°†å½“å‰ä»»åŠ¡çš„æ‰€æœ‰æ—¥å¿—ä¿å­˜åœ¨è¿™ä¸ªå†…å­˜åˆ—è¡¨é‡Œã€‚
        # æ¯æ¬¡æœ‰æ–°æ—¥å¿—ï¼Œappend è¿›è¿™é‡Œï¼Œç„¶åæŠŠæ•´ä¸ªåˆ—è¡¨è¦†ç›–ä¸Šä¼ åˆ°äº‘ç«¯ã€‚
        self.current_task_logs = []

    def _sync_log(self, task_id):
        """
        ğŸ”„ [å†…éƒ¨æ–¹æ³•] æ—¥å¿—åŒæ­¥å™¨
        
        åŠŸèƒ½ï¼šå°†å†…å­˜ä¸­çš„æ—¥å¿—ç¼“å†²åŒº (self.current_task_logs) å…¨é‡æ¨é€åˆ° Supabaseã€‚
        è®¾è®¡å“²å­¦ï¼šé‡‡ç”¨â€œå†…å­˜ä¸ºç‹ï¼Œè¦†ç›–æ›´æ–°â€ç­–ç•¥ï¼Œé¿å…å¤šçº¿ç¨‹ä¸‹çš„æ•°æ®è¦†ç›–é—®é¢˜ã€‚
        """
        try:
            # ç›´æ¥è°ƒç”¨ Update æ¥å£ï¼Œå°† logs å­—æ®µæ›´æ–°ä¸ºå½“å‰çš„å†…å­˜åˆ—è¡¨
            self.supabase.table(self.TABLE_NAME).update({
                "logs": self.current_task_logs
            }).eq("id", task_id).execute()
        except Exception as e:
            # âš ï¸ æ³¨æ„ï¼šæ—¥å¿—åŒæ­¥å¤±è´¥å±äºâ€œéè‡´å‘½é”™è¯¯â€ã€‚
            # å¦‚æœç½‘ç»œæŠ–åŠ¨å¯¼è‡´æ—¥å¿—æ²¡å‘å‡ºå»ï¼Œä¸åº”è¯¥ä¸­æ–­æ ¸å¿ƒè®­ç»ƒä»»åŠ¡ï¼Œæ‰€ä»¥è¿™é‡Œåªæ‰“å°ä¸æŠ›å‡ºå¼‚å¸¸ã€‚
            print(f"âš ï¸ [ç½‘ç»œæŠ–åŠ¨] æ—¥å¿—åŒæ­¥è·³è¿‡: {e}")

    def start(self):
        """
        ğŸš€ [ä¸»å…¥å£] å¯åŠ¨ç›‘å¬å¾ªç¯
        è¿™æ˜¯å¤–éƒ¨è°ƒç”¨çš„å”¯ä¸€å…¥å£ï¼Œå¯åŠ¨åä¼šè¿›å…¥æ­»å¾ªç¯ï¼Œç›´åˆ°è¢«æ‰‹åŠ¨åœæ­¢ã€‚
        """
        print(f"ğŸš€ [CloudWorker] å¯åŠ¨æˆåŠŸ! æ­£åœ¨ç›‘å¬ä»»åŠ¡è¡¨: [{self.TABLE_NAME}]")
        try:
            while True:
                # æ‰§è¡Œä¸€æ¬¡â€œå¿ƒè·³â€æ£€æµ‹
                self._tick()
        except KeyboardInterrupt:
            # æ•è· Ctrl+C ä¸­æ–­ä¿¡å·ï¼Œä¼˜é›…é€€å‡º
            print("\nğŸ›‘ [CloudWorker] æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼ŒæœåŠ¡å·²å…³é—­ã€‚")

    def _tick(self):
        """
        ğŸ’“ [å¿ƒè·³å‡½æ•°] å•æ¬¡è½®è¯¢é€»è¾‘
        """
        try:
            # --- 1. è½®è¯¢æ•°æ®åº“ ---
            # æŸ¥è¯¢æ¡ä»¶ï¼šçŠ¶æ€(status)å¿…é¡»æ˜¯ 'pending' (å¾…å¤„ç†)
            # limit(1)ï¼šæ¯æ¬¡åªå– 1 ä¸ªä»»åŠ¡ï¼Œé¿å…è´ªå¤šåš¼ä¸çƒ‚
            response = self.supabase.table(self.TABLE_NAME)\
                .select("*").eq("status", "pending").limit(1).execute()
            
            # --- 2. åˆ¤æ–­æ˜¯å¦æœ‰ä»»åŠ¡ ---
            if response.data:
                # ğŸ¯ å‘ç°ä»»åŠ¡ï¼ç«‹å³å¤„ç†
                # response.data æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæˆ‘ä»¬å–ç¬¬ä¸€ä¸ªå…ƒç´ 
                self._process_task(response.data[0])
            else:
                # ğŸ’¤ æ²¡æœ‰ä»»åŠ¡ï¼Œä¼‘çœ  3 ç§’
                # é¿å…æ­»å¾ªç¯ç©ºè½¬å¯¼è‡´ CPU å ç”¨ç‡è¿‡é«˜ï¼ŒåŒæ—¶ä¹Ÿå‡å°‘æ•°æ®åº“å‹åŠ›
                time.sleep(3)
                # æ‰“å°ä¸€ä¸ªå°ç‚¹ï¼Œè¯æ˜ç¨‹åºè¿˜æ´»ç€ (å¿ƒè·³æ˜¾ç¤º)
                print(".", end="", flush=True)
                
        except Exception as e:
            # ğŸ›¡ï¸ å®¹é”™å¤„ç†
            # æ¯”å¦‚æ•°æ®åº“æ–­è¿ã€æŸ¥è¯¢è¶…æ—¶ç­‰ï¼Œæ‰“å°é”™è¯¯å¹¶å¼ºåˆ¶ä¼‘æ¯ 5 ç§’ï¼Œé˜²æ­¢é”™è¯¯åˆ·å±
            print(f"\nâš ï¸ è½®è¯¢é”™è¯¯: {e}")
            time.sleep(5)

    def _process_task(self, task):
        """
        âš™ï¸ [æ ¸å¿ƒé€»è¾‘] å¤„ç†å•ä¸ªä»»åŠ¡
        """
        # --- 1. è§£åŒ…ä»»åŠ¡ä¿¡æ¯ ---
        task_id = task['id']            # ä»»åŠ¡å”¯ä¸€ID
        scene_id = task['scene_id']     # åœºæ™¯/é¡¹ç›®ID (ä½œä¸ºæ–‡ä»¶å)
        # è·å–ç”¨æˆ·IDï¼Œå¦‚æœæ•°æ®åº“é‡Œæ²¡å­˜ user_id å­—æ®µï¼Œå°±ç”¨é»˜è®¤å€¼ 'default_user'
        user_id = task.get('user_id', 'default_user') 
        
        print(f"\nğŸ“¥ [æ¥æ”¶ä»»åŠ¡] åœºæ™¯ID: {scene_id} | ä»»åŠ¡ID: {task_id}")

        # --- 2. é‡ç½®æ—¥å¿—ç¼“å†²åŒº ---
        # [é‡è¦] å¼€å§‹æ–°ä»»åŠ¡å‰ï¼Œå¿…é¡»æ¸…ç©ºä¸Šä¸€æ¡ä»»åŠ¡çš„æ®‹ç•™æ—¥å¿—ï¼Œé˜²æ­¢ä¸²å°
        self.current_task_logs = []

        # --- 3. å®šä¹‰å›è°ƒå‡½æ•° (é—­åŒ…) ---
        # è¿™ä¸ªå‡½æ•°ä¼šä¼ ç»™ pipeline.pyï¼Œè®©æ ¸å¿ƒå¼•æ“åœ¨æ·±å±‚ä»£ç é‡Œä¹Ÿèƒ½å‘æ—¥å¿—
        def on_pipeline_log(message):
            # A. æ„é€ æ ‡å‡†æ—¥å¿—å¯¹è±¡ (æ—¶é—´æˆ³ + æ¶ˆæ¯)
            log_entry = {
                "ts": int(time.time()), # å½“å‰ç§’çº§æ—¶é—´æˆ³
                "msg": message
            }
            # B. å†™å…¥æœ¬åœ°å†…å­˜ (æ“ä½œæå¿«ï¼Œç»å¯¹ä¸ä¸¢æ•°æ®)
            self.current_task_logs.append(log_entry)
            
            # C. è§¦å‘äº‘ç«¯åŒæ­¥
            self._sync_log(task_id)

        try:
            # =================== é˜¶æ®µ A: é”å®šä»»åŠ¡ ===================
            # å°†çŠ¶æ€æ”¹ä¸º 'processing'ï¼Œå‘Šè¯‰å…¶ä»– Worker è¿™ä¸ªä»»åŠ¡æˆ‘æ¥äº†ï¼Œåˆ«æŠ¢
            # åŒæ—¶æ¸…ç©º logs å­—æ®µï¼Œå‡†å¤‡å¼€å§‹æ–°çºªå½•
            self.supabase.table(self.TABLE_NAME).update({
                "status": "processing",
                "logs": []
            }).eq("id", task_id).execute()

            # =================== é˜¶æ®µ B: ä¸‹è½½èµ„æº ===================
            on_pipeline_log("æ­£åœ¨ä»äº‘ç«¯ä¸‹è½½è§†é¢‘...")
            
            # æ„é€ æœ¬åœ°å­˜å‚¨è·¯å¾„: ./temp_cache/xxx.mp4
            video_path = self.CACHE_DIR / f"{scene_id}.mp4"
            # æ„é€ äº‘ç«¯ä¸‹è½½è·¯å¾„: user_id/scene_id/raw/video.mp4
            storage_path = f"{user_id}/{scene_id}/raw/video.mp4"
            
            # ä¸‹è½½æ–‡ä»¶æµå¹¶å†™å…¥æœ¬åœ°
            try:
                with open(video_path, 'wb') as f:
                    # ä»æŒ‡å®š Bucket ä¸‹è½½
                    res = self.supabase.storage.from_(self.BUCKET_NAME).download(storage_path)
                    f.write(res)
            except Exception as e:
                # é’ˆå¯¹ä¸‹è½½å¤±è´¥åšç‰¹æ®Šè¯´æ˜ï¼Œæ–¹ä¾¿æ’æŸ¥æ˜¯è·¯å¾„ä¸å¯¹è¿˜æ˜¯ç½‘ç»œé—®é¢˜
                raise RuntimeError(f"è§†é¢‘ä¸‹è½½å¤±è´¥ (è·¯å¾„: {storage_path}): {e}")

            # =================== é˜¶æ®µ C: æ‰§è¡Œå¼•æ“ ===================
            # å‡†å¤‡è¾“å‡ºç›®å½•
            task_output_dir = self.CACHE_DIR / scene_id  # ç›´æ¥ç”¨åœºæ™¯ååšç›®å½•
            
            # å®ä¾‹åŒ–é…ç½®å¯¹è±¡ (Config)
            cfg = PipelineConfig(
                project_name=scene_id,
                video_path=video_path,
                work_root=task_output_dir, # è®¾å®šå·¥ä½œç›®å½•
                enable_ai=True,            # å¼€å¯ AI å¢å¼º
                shared_model_dir=self.MODELS_DIR  # ğŸŸ¢ ä¼ å…¥å…±äº«æ¨¡å‹ç›®å½•
            )
            
            # ğŸ”¥ è°ƒç”¨æ ¸å¿ƒç®¡çº¿! 
            # ä¼ å…¥å›è°ƒå‡½æ•° on_pipeline_logï¼Œå®ç°å®æ—¶æ—¥å¿—
            # ğŸŸ¢ [ä¿®æ”¹ç‚¹ 1] è¿è¡Œ Pipeline å¹¶æ¥æ”¶å…ƒæ•°æ®
            # è¿™é‡Œçš„ run_pipeline ç°åœ¨è¿”å›ä¸¤ä¸ªå€¼: (ply_path, metadata_dict)
            try:
                result = run_pipeline(cfg, log_callback=on_pipeline_log)
                
                # å…¼å®¹æ€§å¤„ç†ï¼šé˜²æ­¢ pipeline è¿˜æ²¡æ”¹æˆè¿”å› tuple å¯¼è‡´æŠ¥é”™
                if isinstance(result, tuple):
                    final_ply_path, metadata = result
                else:
                    final_ply_path, metadata = result, {}
            except Exception as e:
                # å³ä½¿ Pipeline æŠ¥é”™ï¼ˆæ¯”å¦‚è¢« AI æ‹¦æˆªäº†ï¼‰ï¼Œæˆ‘ä»¬ä¹Ÿå°è¯•æ•è·å®ƒè·‘å‡ºçš„ metadata
                # è¿™é‡Œæš‚æ—¶ç®€å•å¤„ç†ï¼Œä¾èµ– result åœ¨æŠ¥é”™å‰æ˜¯å¦å·²ç»äº§ç”Ÿï¼ˆå®é™…æŠ¥é”™æ—¶ result ä¸ä¼šè¿”å›ï¼‰
                # ç”Ÿäº§ç¯å¢ƒä¸‹å¯ä»¥æŠŠ metadata æ”¾åœ¨å¼‚å¸¸å¯¹è±¡é‡ŒæŠ›å‡º
                raise e

            # ğŸŸ¢ [ä¿®æ”¹ç‚¹ 2] ç«‹å³åŒæ­¥ AI åˆ†æç»“æœåˆ°æ•°æ®åº“
            # ä¸ç®¡è®­ç»ƒæ˜¯å¦æˆåŠŸï¼Œåªè¦æœ‰åˆ†æç»“æœï¼Œéƒ½åº”è¯¥å­˜ä¸‹æ¥
            if metadata:
                update_data = {}
                
                # 1. åŒæ­¥åˆ†æ•°
                if "ai_score" in metadata:
                    update_data["quality_score"] = metadata["ai_score"]
                
                # 2. åŒæ­¥æ ‡ç­¾
                if "ai_tags" in metadata:
                    update_data["tags"] = metadata["ai_tags"]
                
                # 3. åŒæ­¥è¯„ä»·åŸå›  (æ–°!)
                if "ai_reason" in metadata:
                    update_data["quality_reason"] = metadata["ai_reason"]
                
                # æ‰§è¡Œæ›´æ–°
                if update_data:
                    self.supabase.table(self.TABLE_NAME)\
                        .update(update_data)\
                        .eq("id", task_id)\
                        .execute()
                    on_pipeline_log(f"âœ… AI è¯„åˆ†å·²åŒæ­¥: {metadata.get('ai_score')}åˆ†")

            # æ ¡éªŒç»“æœï¼šå¦‚æœ pipeline è¿”å› None æˆ–è€…æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯´æ˜è®­ç»ƒæŒ‚äº†
            if not final_ply_path or not Path(final_ply_path).exists():
                raise RuntimeError("Pipeline æ‰§è¡Œç»“æŸï¼Œä½†æœªç”Ÿæˆæœ‰æ•ˆçš„ PLY æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è®­ç»ƒæ—¥å¿—ã€‚")

            # =================== é˜¶æ®µ D: ä¸Šä¼ ç»“æœ ===================
            on_pipeline_log("è®­ç»ƒå®Œæˆï¼Œæ­£åœ¨ä¸Šä¼ ç»“æœåˆ°äº‘ç«¯...")
            
            # 1. ä¸Šä¼  PLY æ¨¡å‹æ–‡ä»¶
            upload_ply_key = f"{user_id}/{scene_id}/output/point_cloud.ply"
            with open(final_ply_path, 'rb') as f:
                self.supabase.storage.from_(self.BUCKET_NAME).upload(
                    path=upload_ply_key, 
                    file=f, 
                    # x-upsert=true è¡¨ç¤ºå¦‚æœæ–‡ä»¶å·²å­˜åœ¨åˆ™è¦†ç›–
                    file_options={"content-type": "application/octet-stream", "x-upsert": "true"}
                )

            # 2. ä¸Šä¼  transforms.json (ç”¨äºç½‘é¡µé¢„è§ˆ)
            # å‡è®¾è¯¥æ–‡ä»¶åœ¨ PLY åŒçº§ç›®å½•æˆ–é…ç½®æŒ‡å®šçš„ç›®å½•
            if cfg.transforms_file.exists():
                upload_json_key = f"{user_id}/{scene_id}/output/transforms.json"
                with open(cfg.transforms_file, 'rb') as f:
                    self.supabase.storage.from_(self.BUCKET_NAME).upload(
                        path=upload_json_key,
                        file=f,
                        file_options={"content-type": "application/json", "x-upsert": "true"}
                    )
                on_pipeline_log("ä¸Šä¼  transforms.json æˆåŠŸ")

            # =================== é˜¶æ®µ E: å®Œç»“æ’’èŠ± ===================
            # æ›´æ–°çŠ¶æ€ä¸º 'completed'
            self.supabase.table(self.TABLE_NAME).update({
                "status": "completed"
            }).eq("id", task_id).execute()
            
            on_pipeline_log("âœ… ä»»åŠ¡å…¨éƒ¨å®Œæˆ")
            print("âœ… ä»»åŠ¡å®Œæˆ")

        except Exception as e:
            # =================== å¼‚å¸¸å¤„ç† ===================
            print(f"âŒ ä»»åŠ¡å¤„ç†å¤±è´¥: {e}")
            
            # 1. å°è¯•å°†é”™è¯¯ä¿¡æ¯è®°å½•åˆ°äº‘ç«¯æ—¥å¿—ï¼Œè®©ç”¨æˆ·çŸ¥é“æ­»åœ¨å“ªä¸€æ­¥äº†
            try:
                self.current_task_logs.append({"ts": int(time.time()), "msg": f"âŒ ä¸¥é‡é”™è¯¯: {str(e)}"})
                self._sync_log(task_id)
            except:
                pass # å¦‚æœè¿™æ—¶å€™è¿ç½‘éƒ½æ–­äº†ï¼Œå°±æ”¾å¼ƒå†™æ—¥å¿—
            
            # 2. å°†ä»»åŠ¡çŠ¶æ€æ ‡è®°ä¸º 'failed'ï¼Œé¿å…æ­»å¾ªç¯é‡è¯•
            self.supabase.table(self.TABLE_NAME).update({"status": "failed"}).eq("id", task_id).execute()
        
        finally:
            # =================== ğŸ§¹ æ¸…ç†å·¥ä½œ (æ–°å¢é€»è¾‘) ===================
            import shutil # ç¡®ä¿å¼•å…¥ shutil

            # 1. åˆ é™¤æºè§†é¢‘æ–‡ä»¶
            if 'video_path' in locals() and video_path.exists():
                try:
                    os.remove(video_path)
                    print(f"ğŸ—‘ï¸ å·²åˆ é™¤ä¸´æ—¶è§†é¢‘: {video_path.name}")
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤è§†é¢‘å¤±è´¥: {e}")
            
            # 2. åˆ é™¤ä»»åŠ¡è¾“å‡ºç›®å½• (åŒ…å«å›¾ç‰‡ã€COLMAPæ•°æ®ã€PLYç­‰æ‰€æœ‰ä¸­é—´äº§ç‰©)
            # âš ï¸ è­¦å‘Šï¼šå¦‚æœä½ è¿˜æ²¡æœ‰ä¿®æ”¹ ai_segmentor.py è®©æ¨¡å‹ä¸‹è½½åˆ°å…¬å…±ç›®å½•ï¼Œ
            # è¿™é‡Œçš„åˆ é™¤æ“ä½œä¼šæŠŠä¸‹è½½åœ¨é‡Œé¢çš„ AI æ¨¡å‹ä¹Ÿåˆ æ‰ï¼è¯·åŠ¡å¿…å…ˆåšâ€œæ¨¡å‹æ¬å®¶â€ã€‚
            if 'task_output_dir' in locals() and task_output_dir.exists():
                try:
                    shutil.rmtree(task_output_dir)
                    print(f"ğŸ—‘ï¸ å·²æ¸…ç©ºä»»åŠ¡å·¥ä½œåŒº: {task_output_dir.name}")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†å·¥ä½œåŒºå¤±è´¥: {e}")

            # 3. é‡ç½®æ—¥å¿—
            self.current_task_logs = []