# [ä¸šåŠ¡ç±»] å­˜æ”¾ AISegmentor + get_central_object_prompt
import os
import os
import shutil
import json
import cv2
import numpy as np
import torch
from pathlib import Path

# --- 1. è½¯ä¾èµ–å¼•å…¥ (AI åº“) ---
try:
    import dashscope
    from dashscope import MultiModalConversation
    from ultralytics import SAM, YOLOWorld
    HAS_AI = True
except ImportError:
    HAS_AI = False
    print("âš ï¸ [Module Warning] 'dashscope' or 'ultralytics' not found. AI features will be disabled.")

# --- 2. é¡¹ç›®å¼•ç”¨ ---
from src.config import PipelineConfig
# å…³é”®ï¼šå¼•å…¥æ¸…æ´— Mask çš„ç®—æ³•
from src.utils.cv_algorithms import clean_and_verify_mask


def get_central_object_prompt(images_dir: Path, sample_count=3):
    """
    [Step 1.1] ä½¿ç”¨ Qwen-VL-Plus å¤šå›¾åˆ†æï¼Œæå–ä¸­å¿ƒç‰©ä½“çš„æ–‡æœ¬æè¿°
    
    å‚æ•°:
        images_dir (Path): å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
        sample_count (int): é‡‡æ ·å›¾ç‰‡æ•°é‡ï¼Œé»˜è®¤3å¼ ï¼ŒèŠ‚çœ Token å¹¶åŠ å¿«é€Ÿåº¦
    
    è¿”å›:
        prompt_text (str): å¤§æ¨¡å‹ç”Ÿæˆçš„ç‰©ä½“æè¿°æç¤ºè¯
    """
    # è·å– API Key
    api_key = os.environ.get("DASHSCOPE_API_KEY")
    if not api_key:
        print("âŒ æœªè®¾ç½® DASHSCOPE_API_KEYï¼Œæ— æ³•è°ƒç”¨å¤§æ¨¡å‹ã€‚")
        return None

    print(f"\nğŸ§  [AI åˆ†æ] æ­£åœ¨è°ƒç”¨ Qwen-VL-Plus åˆ†æåœºæ™¯...")
    
    # [Python è¿›é˜¶] ä½¿ç”¨ glob è·å–æ‰€æœ‰ jpg/png å›¾ç‰‡ï¼Œå¹¶æ’åºç¡®ä¿é¡ºåºä¸€è‡´
    image_files = sorted(list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.png")))
    if not image_files: return None
    
    # [ç®—æ³•é€»è¾‘] å‡åŒ€é‡‡æ ·ï¼šä½¿ç”¨ numpy çš„ linspace åœ¨å›¾ç‰‡åºåˆ—ä¸­å‡åŒ€æŠ½å– sample_count å¼ å›¾
    # è¿™æ ·èƒ½è¦†ç›–ç‰©ä½“çš„ä¸åŒè§’åº¦ï¼Œæ¯”åªå–å‰ä¸‰å¼ æ›´ç¨³å¥
    indices = np.linspace(0, len(image_files) - 1, sample_count, dtype=int)
    sampled_imgs = [image_files[i] for i in indices]
    
    # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯ä½“ (Dashscope SDK è¦æ±‚çš„æ ¼å¼)
    content = [{"image": str(img_path)} for img_path in sampled_imgs]
    content.append({
        "text": (
            "è¿™äº›æ˜¯ä¸€ä¸ªè§†é¢‘çš„æŠ½å¸§å›¾ç‰‡ã€‚è¯·åˆ†æç”»é¢ä¸­å¿ƒå§‹ç»ˆå­˜åœ¨çš„ã€æœ€ä¸»è¦çš„ä¸€ä¸ªç‰©ä½“æ˜¯ä»€ä¹ˆã€‚"
            "è¯·è¾“å‡ºä¸€ä¸ªé€‚åˆç”¨äºç‰©ä½“æ£€æµ‹æ¨¡å‹çš„è‹±æ–‡åè¯çŸ­è¯­ï¼ˆPromptï¼‰ã€‚"
            "âš ï¸ å…³é”®ç­–ç•¥ï¼šè¯·ä¼˜å…ˆæè¿°ã€è§†è§‰ç‰¹å¾ã€‘ï¼ˆé¢œè‰²ã€æè´¨ã€å½¢çŠ¶ï¼‰ï¼Œè€Œä¸æ˜¯ã€åŠŸèƒ½åç§°ã€‘ã€‚"
            "è¶Šç®€å•ã€è¶Š'åœŸ'çš„è¯ï¼Œæ£€æµ‹æ¨¡å‹è¶Šå®¹æ˜“è¯†åˆ«ã€‚"
            "ä¾‹å¦‚ï¼š"
            " - ä¸è¦è¯´ 'electric shaver' (ç”µåŠ¨å‰ƒé¡»åˆ€)ï¼Œè¯·è¯´ 'gray metal object' æˆ– 'device'ã€‚"
            " - ä¸è¦è¯´ 'portable charger' (å……ç”µå®)ï¼Œè¯·è¯´ 'white rectangular box'ã€‚"
            "è¦æ±‚ï¼šä¸¥æ ¼åªè¾“å‡ºè¿™ä¸ªè‹±æ–‡çŸ­è¯­ï¼Œä¸è¦åŒ…å«ä»»ä½•æ ‡ç‚¹ç¬¦å·ã€è§£é‡Šã€‚"
        )
    })
    
    # å°è£…ç”¨æˆ·æ¶ˆæ¯
    messages = [{"role": "user", "content": content}]

    try:
        # è°ƒç”¨é˜¿é‡Œäº‘ Qwen-VL-Plus æ¨¡å‹
        response = dashscope.MultiModalConversation.call(
            model='qwen-vl-plus', 
            messages=messages
        )
        
        # è§£æè¿”å›ç»“æœ
        if response.status_code == 200:
            # æå–æ–‡æœ¬å†…å®¹
            prompt_text = response.output.choices[0].message.content[0]["text"].strip()
            # [æ•°æ®æ¸…æ´—] å»æ‰å¯èƒ½å­˜åœ¨çš„æ ‡ç‚¹ç¬¦å·ï¼Œé˜²æ­¢å¹²æ‰° YOLO
            prompt_text = prompt_text.replace(".", "").replace('"', "").replace("'", "")
            # \033[92m æ˜¯ ANSI è½¬ä¹‰ç ï¼Œç”¨äºåœ¨æ§åˆ¶å°è¾“å‡ºç»¿è‰²æ–‡å­—
            print(f"    ğŸ¤– Qwen è®¤ä¸ºä¸­å¿ƒç‰©ä½“æ˜¯: [ \033[92m{prompt_text}\033[0m ]")
            return prompt_text
        else:
            print(f"âŒ Qwen è°ƒç”¨å¤±è´¥: {response.code} - {response.message}")
            return None
    except Exception as e:
        print(f"âŒ API è¿æ¥å¼‚å¸¸: {e}")
        return None


class AISegmentor:
    def __init__(self, cfg: PipelineConfig):
        self.cfg = cfg
        self.data_dir = cfg.data_dir
        self.images_dir = cfg.images_dir
        self.masks_dir = cfg.masks_dir

    def run(self):
        """æ‰§è¡Œ AI åˆ†å‰²æ€»æµæ°´çº¿ (å¯¹åº”åŸ run_ai_segmentation_pipeline)"""
        if not HAS_AI or not self.cfg.enable_ai:
            print("â© è·³è¿‡ AI åˆ†å‰² (æœªå¯ç”¨æˆ–ç¼ºå°‘ä¾èµ–)")
            return False
            
        if not self.cfg.transforms_file.exists():
            print("âš ï¸ transforms.json ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œ AI åˆ†å‰²")
            return False

        print(f"\nâœ‚ï¸ [AI åˆ†å‰²] æ­£åœ¨åˆå§‹åŒ–...")
        self.masks_dir.mkdir(parents=True, exist_ok=True)

        # 1. è·å–æç¤ºè¯
        text_prompt = self._get_prompt()
        
        # 2. åŠ è½½æ¨¡å‹
        try:
            # è‡ªåŠ¨è¿ç§»æ¨¡å‹æ–‡ä»¶é€»è¾‘
            self._ensure_model_exists("yolov8s-worldv2.pt")
            self._ensure_model_exists("sam2.1_l.pt")
            
            yolo_path = self.cfg.work_root / "yolov8s-worldv2.pt"
            sam_path = self.cfg.work_root / "sam2.1_l.pt"
            
            print("    -> æ­£åœ¨åŠ è½½ AI æ¨¡å‹...")
            det_model = YOLOWorld(str(yolo_path))
            det_model.set_classes([text_prompt])
            sam_model = SAM(str(sam_path))
        except Exception as e:
            print(f"âŒ AI æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

        # 3. è¯»å–å…ƒæ•°æ®
        with open(self.cfg.transforms_file, 'r') as f: meta = json.load(f)
        frames_map = {Path(f["file_path"]).name: f for f in meta["frames"]}
        
        image_files = sorted(list(self.images_dir.glob("*.jpg")) + list(self.images_dir.glob("*.png")))
        valid_frames_list = []
        deleted_count = 0
        
        print(f"    -> å¼€å§‹å¤„ç† {len(image_files)} å¼ å›¾ç‰‡...")

        # 4. å¾ªç¯å¤„ç†
        for i, img_path in enumerate(image_files):
            try:
                # YOLO æ£€æµ‹
                det_results = det_model.predict(img_path, conf=0.05, verbose=False)
                bboxes = det_results[0].boxes.xyxy.cpu()
                
                # ç­›é€‰ä¸­å¿ƒæ¡† (é€»è¾‘ä¸ä¹‹å‰ç›¸åŒï¼Œè¿™é‡Œç®€åŒ–å±•ç¤º)
                if len(bboxes) > 1:
                    bboxes = self._pick_center_box(bboxes, det_results[0].orig_shape)
                
                # SAM åˆ†å‰²
                if len(bboxes) == 0:
                    # ä¸­å¿ƒç‚¹æ¨¡å¼
                    h, w = det_results[0].orig_shape[:2]
                    cx, cy, margin = w / 2, h / 2, 5
                    bboxes = [[cx-margin, cy-margin, cx+margin, cy+margin]]
                
                sam_results = sam_model(img_path, bboxes=bboxes, verbose=False)
                
                # åˆå¹¶ Mask
                if sam_results[0].masks is not None:
                    final_mask = np.any(sam_results[0].masks.data.cpu().numpy(), axis=0).astype(np.uint8) * 255
                else:
                    final_mask = np.zeros(det_results[0].orig_shape[:2], dtype=np.uint8)

                # æ¸…æ´— Mask (è°ƒç”¨å†…éƒ¨æ–¹æ³•)
                is_good, cleaned_mask, reason = self._clean_and_verify_mask(final_mask)
                
                if is_good:
                    final_name = self._save_transparent_png(img_path, cleaned_mask)
                    if img_path.name in frames_map:
                        frame_data = frames_map[img_path.name]
                        frame_data["file_path"] = f"images/{final_name}"
                        valid_frames_list.append(frame_data)
                else:
                    print(f"       ğŸ—‘ï¸ [å‰”é™¤] {img_path.name}: {reason}")
                    img_path.unlink()
                    deleted_count += 1

            except Exception as e:
                print(f"       âŒ é”™è¯¯ {img_path.name}: {e}")
                continue
            
            if i % 10 == 0: print(f"       è¿›åº¦: {i}/{len(image_files)}...", end="\r")

        # 5. æ›´æ–° json
        if valid_frames_list:
            meta["frames"] = valid_frames_list
            with open(self.cfg.transforms_file, 'w') as f: json.dump(meta, f, indent=4)
            print(f"\n    âœ… AI å¤„ç†å®Œæˆï¼Œå‰©ä½™å¯ç”¨: {len(valid_frames_list)}")
            return True
        else:
            print("\nâŒ é”™è¯¯ï¼šæ‰€æœ‰å›¾ç‰‡éƒ½è¢«å‰”é™¤äº†")
            return False

    def _get_prompt(self):
        """åŸ get_central_object_prompt çš„å°è£…"""
        # è¿™é‡Œä½ å¯ä»¥è°ƒç”¨ä¹‹å‰å®šä¹‰çš„å…¨å±€å‡½æ•° get_central_object_prompt(self.images_dir)
        # æˆ–è€…æŠŠé‚£æ®µä»£ç æ¬è¿›æ¥ã€‚ä¸ºäº†çœäº‹ï¼Œå»ºè®®ç›´æ¥è°ƒç”¨ç°æœ‰çš„å…¨å±€å‡½æ•°ï¼š
        try:
            prompt = get_central_object_prompt(self.images_dir)
            return prompt if prompt else "central object"
        except:
            return "central object"

    def _ensure_model_exists(self, model_name):
        target = self.cfg.work_root / model_name
        local = Path(__file__).parent / model_name
        if not target.exists() and local.exists():
            shutil.copy2(str(local), str(target))

    def _pick_center_box(self, bboxes, img_shape):
        """ç­›é€‰æœ€ä¸­å¿ƒçš„æ¡†"""
        import torch
        img_h, img_w = img_shape[:2]
        screen_center = torch.tensor([img_w / 2.0, img_h / 2.0])
        min_dist = float('inf')
        best_idx = 0
        for idx, box in enumerate(bboxes):
            cx = (box[0] + box[2]) / 2.0
            cy = (box[1] + box[3]) / 2.0
            dist = torch.sqrt((cx - screen_center[0])**2 + (cy - screen_center[1])**2)
            if dist < min_dist:
                min_dist = dist
                best_idx = idx
        return bboxes[best_idx].unsqueeze(0)

    def _clean_and_verify_mask(self, mask):
        """åŸ clean_and_verify_mask çš„å°è£…"""
        # ç›´æ¥è°ƒç”¨ä¹‹å‰çš„å…¨å±€å‡½æ•°å³å¯
        return clean_and_verify_mask(mask)

    def _save_transparent_png(self, img_path, mask):
        """åˆæˆå¹¶ä¿å­˜ PNG"""
        img = cv2.imread(str(img_path))
        mask_blurred = cv2.GaussianBlur(mask, (5, 5), 0)
        alpha = mask_blurred.astype(np.float32) / 255.0
        img_float = img.astype(np.float32)
        b, g, r = cv2.split(img_float)
        img_bgra = cv2.merge([
            (b * alpha).astype(np.uint8),
            (g * alpha).astype(np.uint8),
            (r * alpha).astype(np.uint8),
            mask_blurred
        ])
        new_path = img_path.with_suffix('.png')
        cv2.imwrite(str(new_path), img_bgra)
        if img_path.suffix.lower() == '.jpg':
            try: img_path.unlink()
            except: pass
        return new_path.name
        